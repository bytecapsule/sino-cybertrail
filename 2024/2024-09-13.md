# 2024-09-13

## 1


蹭下热度谈谈OpenAIo1的价值意义及RL 的Scaling law。

一.OpenAI o1是大模型的巨大进步

1.1我觉得OpenAI o1是自GPT 4发布以来，基座大模型最大的进展，逻辑推理能力提升的效果和方法比预想的要好，GPT 4o和o1是发展大模型不同的方向，但是o1这个方向更根本，重要性也比GPT 4o这种方向要重要得多，原因下面会分析。

1.2为什么说o1比4o方向重要？这是两种不同的大模型发展思路，说实话在看到GPT 4o发布的时候我是有些失望的，我当时以为OpenAI会优先做o1这种方向，但是没想到先出了GPT 4o。GPT 4o本质上是要探索不同模态相互融合的大一统模型应该怎么做的问题，对于提升大模型的智力水平估计帮助不大；而o1本质上是在探索大模型在AGI路上能走多远、天花板在哪里的问题，很明显第二个问题更重要。

GPT 4o的问题在于本身大模型的智力水平还不够高，所以做不了复杂任务，导致很多应用场景无法实用化，而指望靠图片、视频这类新模态数据大幅提升大模型智力水平是不太可能的，尽管确实能拓展更丰富的多模态应用场景，但这类数据弥补的更多是大模型对外在多模态世界的感知能力，而不是认知能力。提升大模型认知能力主要还要靠LLM文本模型，而提升LLM模型认知能力的核心又在复杂逻辑推理能力。LLM的逻辑推理能力越强，则能解锁更多复杂应用，大模型应用的天花板就越高，所以不遗余力地提升大模型尤其是文本模型的逻辑能力应该是最重要的事情，没有之一。

 如果o1模型能力越做越强，则可以反哺GPT 4o这种多模态大一统模型，可以通过直接用o1基座模型替换GPT 4o的基座、或者利用o1模型生成逻辑推理方面的合成数据增强GPT 4o、再或者用o1蒸馏GPT 4o模型….. 等等，能玩的花样应该有很多，都可以直接提升GPT 4o的复杂任务解决能力，从而解锁更复杂的多模态应用场景。OpenAI未来计划两条线，一条是o1，一条是GPT 4o，它的内在逻辑大概应该是这样的，就是说通过o1增强最重要的基座模型逻辑推理能力，而再把这种能力迁移到GPT 4o这种多模态通用模型上。

1.3 OpenAI o1的做法本质上是COT的自动化。我们知道，通过COT把一个复杂问题拆解成若干简单步骤，这有利于大模型解决复杂逻辑问题，但之前主要靠人工写COT来达成。从用户提出的问题形成树的根结点出发，最终走到给出正确答案，可以想像成类似AlphaGo下棋，形成了巨大的由COT具体步骤构成的树形搜索空间，这里COT的具体步骤的组合空间是巨大的，人写的COT未必最优。如果我们有大量逻辑数据，是由<问题，明确的正确答案>构成，则通过类似AlphaGo的Monte Carlo Tree Search（MCTS）搜索+强化学习，确实是可以训练大模型快速找到通向正确答案的COT路径的。

而问题越复杂，则这个树的搜索空间越大，搜索复杂度越高，找到正确答案涉及到的COT步骤越多，则模型生成的COT就越复杂，体现在o1的速度越慢，生成的COT Token数越多。很明显，问题越复杂，o1自己生成的隐藏的COT越长，大模型推理成本越高，但效果最重要，成本其实不是问题，最近一年大模型推理成本降低速度奇快，这个总有办法快速降下去。

1.4 从上面o1的做法可以知道Prompt工程会逐渐消亡。之前解决复杂问题，需要人写非常复杂的Prompt，而o1本质上是COT等复杂Prompt的自动化，所以之后是不太需要用户自己构造复杂Prompt的。本来让用户写复杂Prompt就是不人性化的，所有复杂人工环节的自动化，这肯定是大势所趋。

1.5 Agent属于概念火但无法实用化的方向，主要原因就在于基座模型的复杂推理能力不够强。如果通过基座模型Plan把一个复杂任务分解为10个步骤，哪怕单个步骤的正确率高达95%，要想最后把任务做对，10个环节的准确率连乘下来，最终的正确率只有59%，惨不忍睹。那有了o1是不是这个方向就前途坦荡？也是也不是，o1的Model Card专门测试了Agent任务，对于简单和中等难度的Agent任务有明显提升，但是复杂的、环节多的任务准确率还是不太高。就是说，不是说有了o1 Agent就现状光明，但是很明显o1这种通过Self Play增强逻辑推理能力的方向应该还有很大的发展潜力，从这个角度讲说Agent未来前途光明问题应该不大。

1.6 OpenAI很多时候起到一个行业指路明灯的作用，往往是第一个证明某个方向是行得通的（比如ChatGPT、GPT 4、Sora、GPT 4o包括这次的o1），然后其他人开始疯狂往这个方向卷，到后来甚至卷的速度太快把OpenAI都甩到后面吃尾气。典型例子就是Sora，如果OpenAI不是出于阻击竞争对手秀一下肌肉，大家都没有意识到原来这个方向是可以走这么远的，但当意识到这一点后，只要你专一地卷一个方向，方向明确且资源聚焦，是可能赶超OpenAI的，目前国内外各种视频生成模型有些甚至可能已经比Sora好了，Sora至今仍然是期货状态，主要OpenAI想做的方向太多，资源分散导致分到具体一个方向的资源不够用，所以越往后发展期货状态的方向越多，也让人觉得尽显疲态。

OpenAI o1等于给大家又指出了一个前景光明的方向，估计后面大家又开始都往这个方向卷。我觉得卷这个方向比去卷GPT 4o和视频生成要好，虽然具体怎么做的都不知道，但是大方向清楚且效果基本得到证明，过半年肯定头部几家都能摸清具体技术追上来，希望能再次让OpenAI吃尾气。而且这个方向看上去资源耗费应该不会特别大，偏向算法和数据一些，数据量规模估计不会特别巨大，卷起来貌似成本低一些。这是个卷的好方向。

二.预训练Scaling Law的来源及O1提到的RL Scaling law

2.1粗分的话，大语言模型最基础的能力有三种：语言理解和表达能力、世界知识存储和查询能力以及逻辑推理能力（包括数学、Coding、推理等理科能力，这里Coding有一定的特殊性，是语言能力和逻辑掺杂在一起的混合能力，Coding从语言角度可以看成一种受限的自然语言，但是混杂着复杂的内在逻辑问题。从语言角度看，Coding貌似是容易解决的，从逻辑角度看又相对难解决。总之，Coding目前看是除了语言理解外，大模型做得最好的方向）。

 语言理解和表达是LLM最强的能力，初版ChatGPT就可以完全胜任各种纯语言交流的任务，基本达到人类水准，目前即使是小模型，在这方面比大模型能力也不弱；世界知识能力虽说随着模型规模越大效果越好，但幻觉问题目前无法根治，这是制约各种应用的硬伤之一；逻辑推理能力一直都是LLM的弱项，也是最难提升的方面，从GPT 4开始往后，如何有效并大幅提升LLM的逻辑推理能力是体现不同大模型差异和优势的最核心问题。所以，大模型最重要的一个是世界知识方面如何有效消除幻觉，一个是如何大幅提升复杂逻辑推理能力。语言能力已不是问题。

2.2从大模型的基础能力，我们再说回已经被谈滥了的大模型Scaling law。现在普遍认为通过增加数据和模型规模来提升大模型效果的Scaling law模式，其增长速度在放缓。其实我们对照下大模型的三个基础能力的能力来源，基本就能看出来这是为啥（以下是我猜的，不保真）：

本质上大模型的能力来源都来自训练数据，包含能体现这方面能力的训练数据越多，则这种能力越强。语言能力不用说了，任意一份预训练数据，其中都包含相当比例的语言的词法句法等成分，所以训练数据中体现语言能力的数据是最多的，这也是为何大模型的语言能力最强的原因。

 而数据中包含的世界知识含量，基本是和训练数据量成正比的，明显数据量越多，包含的世界知识越多，Scaling law是数据中包含的世界知识含量关系的一个体现，但是这里有个问题，大模型见过越多数据，则新数据里面包含的新知识比例越小，因为很多知识在之前的数据里都见过了，所以随着数据规模增大，遇到的新知识比例就越低，在世界知识方面就体现出Scaling law的减缓现象。

为啥逻辑推理能力最难提升？因为能体现这方面的自然数据（代码、数学题、物理题、科学论文等）在训练数据中比例太低，自然大模型就学不好，尽管通过不断增加数据，能增加逻辑推理方面数据的绝对数量，但因为占比太少，这方面提升的效果和增加的总体数据规模就不成比例，效果也不会太明显，就体现在逻辑推理能力Scaling law看上去的放缓。这是很自然的。这也是为何现在为了提高模型逻辑能力，往往在预训练阶段和Post-training阶段，大幅增加逻辑推理数据占比的原因，且是有成效的。

2.3 所以目前大模型的核心能力提升，聚焦到不断通过合成数据等方式构造更多比例的逻辑推理数据上来。但是大部分逻辑推理数据的形式是<问题，正确答案>，缺了中间的详细推理步骤，而o1本质上是让大模型学会自动寻找从问题到正确答案的中间步骤，以此来增强复杂问题的解决能力。

OpenAI o1提到了关于RL在训练和推理时候的Scaling law，并指出这与预训练时候的Scaling law具有不同特性。很明显，如果o1走的是MCTS搜索技术路线，那么把COT拆分的越细（增加搜索树的深度），或提出更多的可能选择（节点的分支增多，就是说树的宽度越宽），则搜索空间越大，找到好COT路径可能性越大，效果越好，而训练和推理的时候需要算力肯定越大。看上去有着效果随着算力增长而增长的态势，也就是所谓的RL的Scaling law。这其实是树搜索本来应有之义，我倒觉得把这个称为RL的Scaling law有点名不副实。






## 2


技术解读OpenAI最新“理科生”大模型o1，类似围棋AI的搜索

1. 新推出的o1在数学和编程上达到了人类精英水平，科学问答博士水平、编程奥赛能拿牌、全美数学竞赛前500名。简单地说，就是“理科生”能力很强，远远超过其它AI。文科生水平，就和之前的GPT-4o差不多，或者给人类评估者感觉差一些。

2. 技术秘诀，在于解构模拟了理科生的思维模式：思维链。文科问题是没有什么思维链的，就是不断输出“下一个词”，凑出句子、段落，熟练了就能扯很长。但是理科问题是需要很长的思维链条的，一步推一步，最后得到满意的答案。

3. 神奇的是，机器是可以把这个思维链条模拟出来的！其实我们看大模型做一些简单数学题、逻辑题，回答就包括了完整的思维链条。要注意，这些不是抄答案！有水平的理科生是不能抄答案的，题目变化无穷多。机器给出的，确实是符合人类能理解的思维链。

4. 但是，机器其实不知道自己在干什么！它只是进行了“思维链展开”这个操作。理科生的答案，最终还是文字表述的，一步推一步，每步之间是有文字关联的，机器能“形式主义”地学会。虽然不知道物理和数学实质上什么意思，但是这个链条步骤是人类测试者喜欢的。

5. 一个问题，可能的“思维链展开”有极多种，其中绝大多数都是无效的，链条推理不严谨或者是错误的。但是这就构造了一个庞大的“解空间”，可以在里面优化努力。OpenAI应该是开发了一种理科生模式，让机器在解空间里搜索优化，比文科模式花的时间要长得多。

6. 一个类比就是围棋AI，下棋有“直觉模式”和“搜索模式”。AI的直觉模式就是看棋型直接给出候选点，是一个神经网络的结果，下得很快，能战胜我这样水平不高（但也不低）的业余棋手（因为我们也是靠直觉下棋，算不太动了），但是打不过发现有问题就仔细计算的人类高手。而基于MCTS（蒙特卡洛树形搜索）的搜索算法，就能轻松打败人类，机器自己对弈（强化学习）提升到了人类无法想象的高水平。这次的o1就是引入了搜索模式。

7. 搜索模式会展开思维链，在里面选择概率上似乎更好的链条进行验证、继续展开。因为有随机因素，所以选的链条多半有问题。但是它会继续搜索，总会弄出一些在它自己看来还不错的思维链条，输出给人类。这个搜索算法做好以后，很多数学和编程问题真的就是正确答案。

8. o1也能有强化学习机制，不同版本比较答案正确率，自我迭代。它不依赖很多语言样本了，就是需要改进思维链搜索算法。等于理科生反复做题，找到自己擅长的思路，改正不对的思维习惯。

9. 这确实是机器解构人类理科思维的重大进展，把理科问题像下围棋那样解构成了思维链空间。而这是机器擅长的，等于暴力破解了解空间。人类绝对不会这样下棋、思考，会累死。机器成功模拟了理科生思维，虽然还是不理解在干什么。理论上来说，机器可以超过最厉害理科生的思维能力，暴力搜索模拟思维，然后把结果给人展示，人类会给出真正的智慧“理解问题和答案是什么”。也就是说，机器是极为厉害的“思维工具”，能够帮助人类拓展思维能力，这个空间打开了。我确认这是一个重要的AI领域的大进展。






## 3


直播电商似乎成为一种工业鸦片。它们将商品以极其低廉的价格提供给大众，享受了美德的声誉。

然而这种所谓的实惠留给消费者的做法，容易将整个社会从一个健康的纺锤形，变成一个细腰葫芦。少数者越来越富有，中间层在减少，底层则不断扩大。

中国零售电商渗透率超过50%。这种渗透率，会摧毁底层夫妻店的小店生意。让中产下沉，让小店消失。

 光天化日之下 的压榨，不断让消费者上瘾，而且叫好。他们没有注意到，在那些看不见的工厂、餐饮等商品和服务提供者，利润被平台压榨得越来越低，无法再为他们的亲朋提供有效的工作。或者说，消费者本人在这里享受了针头线脑的实惠，却在另外一个地方丢失了工作。

一个社会最健康的特征可以包容多元分层结构，每个分层都有一类人可以用自己的技能可以自食其力。

最畸形的方式是无法创新的一类平台化经济。它只有一种形式，那就是零售。所谓点到点销售，压扁了中间所有的层级。原来大量小公司的分销，导购员，营销、夫妻店邻里亲情维护等无数技能分层，全部消失。

在平台-快递-消费者这样一个三层最简单的经济结构下，大量层级拥有的各种技能都不重要，它们只需要拥有单一的体力：快递。

极其少数技能的人被优选集中到平台之中，大量类似技能的人，被废黜到工蚁阶层。

中低产阶层的空心化，是一种可怕的社会癌症。

零售在线渗透率低一点，对普通百姓店是一种保护。每个国家都要有力的去保护这些最底层的小业主。他们糊口的方式如此简单，但却又如此重要。电商比例不能过于扩大，就是出于这种保护。

美国的电商比例2023年只有15%。而且即使每年提升，但每年也只突破一个点。2030年才达到20%左右。同样，英国UK的在线零售率，在2021年达到34%，也进入稳步调整状态。目前还掉下来为30%。然后一直未来10年稳定在30%左右。每年突破0.1个百分点。

美国只突破一个点。英国每年只突破0.1个点。无论是1%，还是0.1%的缓慢增长，骨子里都是社会底层老百姓夫妻店的福音。

在线零售电商很容易蜕变成披着高科技外衣的房地产商。它们有同样的杠杆力量，可以挤压制造商和服务商。然而这是一种更加隐蔽的方式。

如果他们积累的资金一部分不能转向创新科技，那么这样的财富积累可能也是一种对社会底层的无情打劫。






## 4


根据美国统计局前两天发布的数据：

（ps：关于“户”和“家庭”的区别，请搜索以前发过的微博）

2023年，美国每“户”中位数年收入：80610美元，扣除通胀后，比2022年增长4.0%（税后中位数69240美元）

其中：

“家庭户”中位数102800美元（税后88650美元）

“非家庭户”中位数49600美元（税后42650美元）

“家庭户”中，“已婚家庭户”的中位数是119400美元（税后101500美元）

本土出生的户均中位数是81700美元（税后70190美元）

其他国家出生的美国公民，户均中位数86060美元（税后74170美元），非公民户均61440美元（税后55380美元）

（ps：关于“户”和“家庭”的区别，请搜索以前发过的微博）

亚裔最高，中位数每户112800美元（税后94810美元）

白人89050（税后75920），西裔65540（税后58240），黑人56490（税后49830）

本科及以上学历，中位数每户126800美元（税后104300美元）

图4：整体贫富差距略微缩小，收入越低的群体收入占比提升越大

图5：全职工作的人员里，男女收入差距缓慢持续缩小，目前女性收入是男性的82.7%

2023年，有14.4%的“户”，收入超过20万美元

其中：白人有16.3%，黑人7.3%，亚裔26.9%，西裔8.3%

如图6：31.6万美元年收入（税后23.72万），可以排到美国“户”的前5%，倒数百分之10%是18980美元

不看“户”，具体到单个劳动者的话，如图7：

男性工作者总共有9127万人，中位数年收入56280美元

男性全职工作者总共有6857万人，中位数年收入66790美元

女性工作者总共有8179万人，中位数年收入42110美元

女性全职工作者总共有5285万人，中位数年收入55240美元






