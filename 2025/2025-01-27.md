# 2025-01-27

🔻有些人试图用“某个问题答不好”或者“输入不友好”之类个例尝试证明 deepseek“不行”，纯属没招了。

🔻让我来通俗解释一下deepseek 的创新意义何在。

🔻在此之前，欧美厂商给大众和投资人灌输的故事是：训练顶级人工智能模型的成本非常昂贵，“技术进步=堆叠算力”。OpenAI、Anthropic 等公司仅在计算方面就花费了以亿为单位的美元。他们需要大规模的数据中心，配备成千上万个价值 4 万美元的高性能AI GPU。这就好比需要整个发电厂才能运行一家工厂。

🔻而美国就高性能AI GPU出口对我们进行了制裁。

🔻特朗普上任后，拉来软银、OpenAI、甲骨文等搞出一个星际之门的人工智能投资大画饼，号称投资5000亿美元，声称要为这个项目的计算中心“配套5座核电站”。马斯克质疑OpenAI也只是说“它们没这么多钱”，而不是否认“需要花这么多钱”。

🔻然后DeepSeek 出现了，Deepseek说：“如果我们用 不那么多的训练成本和不那么高端的GPU来做这件事呢？”

🔻他们不只是说说而已，而是真的做了，去年发布了V3（训练成本557.6万美元），在星际之门计划宣布后，他们又发布了推理模型R1，他们的模型在许多任务上都与 GPT-4 和Claude不相上下，甚至有过之而无不及。

🔻整个世界人工智能世界震撼了。

🔹如何做到？他们从训练工程的根本上重新思考了一切。

🔹首先是提出了一种低成本、高能效的 AI-HPC 架构，通过软硬件协同设计在 PCIe 架构下实现接近 NVLink 互联的性能，意思就是自己攒了超算，论文设计是“基于 10,000 个 PCIe A100 GPU 构建的大规模集群，通过优化网络拓扑（如双层 Fat-Tree 和 InfiniBand 互联）和存储-计算整合网络，实现与英伟达 DGX-A100 相近的性能，但成本降低 50%、能耗减少 40%”（图1）

🔹然后，传统的A就像把每个数字都写成小数点后 32 位。DeepSeek 就说：“如果我们只用 8 位呢？还是足够精确！”嘭，所需的内存减少了 75%，从结构到量化的压缩，MLA、FP8、DualPipe、Aux-loss-free等等一起上，能压就压。

🔹接下来是他们的“多token预测”系统（MTP）。正常的人工智能读起来就像一年级的小学生：“猫......坐在......灶台上……的铁锅里”，DeepSeek 能一次性理解和生成整句整段，同时预测和生成多个连续位置的token，推理速度快 1.8 倍，准确率高达 90%。当你要处理数十亿字时，这就很重要了。

🔹但真正聪明的地方在这里：他们建立的是混合专家（MoE）架构，他们不需要一个庞大的人工智能去了解一切，而是需要时才唤醒。DeepSeek 总共有 671B 个参数，但只有 37B 个参数同时处于实际激活状态。这就好比你有一个庞大的团队，但每项任务只调用你真正需要的专家。

🔹类似 AlphaZero 的“冷启动”策略是 R1的亮点，模型从零开始通过 RL 学习复杂任务，而非模仿人类标注数据。这一过程促使模型在训练中期出现“顿悟时刻”（aha moment），自发优化解题策略并动态分配推理时间。R1-Zero 是首个完全通过大规模强化学习（RL）训练的大模型，无需依赖传统的监督微调阶段。这一方法使模型自主探索推理路径，并涌现出自我验证、反思、生成长链式思维（CoT）等能力。作为唯一支持实时联网搜索的推理模型，联网搜索扩展了应用场景，可直接整合外部信息增强答案准确性。

🔻成果令人惊叹：

🔹- 训练费用：数千万至上亿美元 → 500 万美元

🔹- 需要 GPU：100,000 → 2,000 

🔹- API 成本：便宜 95 %

🔹- 可在更低级的图形处理器而非数据中心级硬件上运行

🔻它打破了“只有大型科技公司才能玩人工智能”的模式（尤其是在模型进入强化学习时代后，o1的成本更是高得难以让人向下进入日常），你不再需要价值数十亿美元的数据中心了。更好的投入与产出平衡可以让更多的 AI 算法理论创新以更便宜的价格、更快的速度在工程上实现。

🔻对于 Nvidia 来说，这太可怕了。他们的整个商业模式都建立在销售利润率高达 90% 的超级昂贵 GPU 上。如果大家突然都能用普通 GPU 干过去不能干的活……那么大型科技公司的护城河就会变成水坑了。

🔻这是一个典型的弯道超车故事：现有公司陷入现有流程的路径依赖，而超车者则重新思考基本方法。DeepSeek 说：“如果我们用数学公式进行更聪明的思考，而不是堆叠算力，结果会怎么样？”

🔻最后是开源玩家最热爱的部分：全面开源与技术透明！模型蒸馏技术！公开模型权重、训练代码及技术细节，支持开发者自由修改与商用，蒸馏降低部署门槛。

🔻如果你质疑 Deepseek R1，她的一切都是开源的，去看看代码，读读论文，聪明人已经赚上钱了，酸人还在写酸文。

🔻这才是真正的技术普惠，为所有的 AI 使用者——注意，是所有，提供了可复现的高性能模型开发路径。像 OpenAI 和 meta 这样的巨头当然不会停滞不前，他们可能已经部署了好几天 R1 的源代码，全员加班、复刻和实现更多的创新了。

🔻但是，开源就是最好的宣传，对于老黄来说，潘多拉之盒已经打开，再也回不到“只需投入更多 GPU ”的 AI 泡沫之路上去了。

🔻图2是 R1 论文里出现的 deepseek 团队，他们真的把整个队伍都列出来了。大多数都很年轻，来自中国一流大学，有些还是在读博士生、硕士生。他们有一个共同点：绝大部分都没有海外学术或工作背景，曾有人戏称：AI 的竞争是中国人才与去美国的中国人才间的竞争，而现在，去美国的中国人才越来越少了。他们在没有全球背景的情况下取得的突破，预示着未来几十年，中国将在科技、工程和数学（STEM）毕业生的数量上占据绝对优势。

🔻最后，特别鸣谢：感谢弱智吧中筛选出的狡猾文本对提升中国大型语言模型推理和理解能力的贡献（图3-9）

🔻谢谢东大开源。
