# 2024-10-09

## 1

很多人在成年后都会面临一个困惑，为啥父母宁愿相信外人，也不相信我们。他们甚至会瞒着我们，做一些极其愚蠢的决定，蠢到他们但凡问我们一句，都不至于被骗得倾家荡产遍体鳞伤。而且即使被骗被欺负，很多父母仍不知悔改，一头撞在南墙上，嘴硬到底。我的一个感受是随着他们年龄的增大，虽然心智都下降了，但一些毫无意义的自尊心却在肆意疯长，还是企图用各种手段来维持他们作为家长的威严，来延续他们辛苦建立起来的家庭阶级。正是他们的一句句“你别问”“你别管”“你懂啥”才让骗子有了可乘之机。那些骗子个个装得温文尔雅仙风道骨，整日喝茶瑜伽吃斋念佛，但其实都是些披着人皮的畜生，它们没有长半点人心。父母从它们那里获得一点可怜的“情绪价值”，最终被它们拿着虚无缥缈的饵料诱出贪念，被敲骨食髓，被骗到家破人亡。我打下这些字恨不得把牙咬碎，你不知道这段话背后，有我的多少血泪。

## 2

今天刷到很多博主在说物理奖不应该颁给计算机科学家，因为他的理论“不够物理”。说这些话的博主肯定物理很厉害了。大家都知道，诺贝尔奖是没有计算机科学的，但计算机科学中有不少理论都受了物理学的启发， 例如： Quantum Computing， Neural Networks， Quantum Cryptography 等等。下面我们来看看 Geoffrey Hinton 的杰作之一：Boltzmann machine 

这里有一个通俗易懂的Boltzmann machine 教程 blog.paperspace.com/beginners-guide-to-boltzmann-machines-pytorch/

玻尔兹曼机是一种受物理学启发的神经网络模型，用来发现数据中的模式。它通过调整连接来学习，基于“能量”概念，能量越低表示解决方案越好。与典型的神经网络不同，它没有明确的输入输出结构，而是通过相互连接的单元重构输入数据，每个单元可以处于“开”或“关”的状态。尽管其复杂性较高，它对维度缩减和解决约束满足问题特别有用.  人们常说，玻尔兹曼机处于深度学习和物理学的交汇点。这些模型基于并行处理方法，广泛应用于维度缩减、分类、回归、协同过滤、特征学习和主题建模 

[我念博士的时候刚接触到Boltzmann machine，觉得这个方法特别fascinating and beautiful]

受限玻尔兹曼机（RBM）在物理学中常被使用，因为它源自统计力学，并且能够模拟具有复杂相互作用的系统。RBM基于能量最小化这一物理学原则，帮助寻找系统的最优状态。这使其特别适合用于理解和模拟物理现象，如相变、量子力学以及粒子的行为。此外，RBM的高效并行处理能力使其能够处理物理学中常见的大规模、高维度数据。

以下是受限玻尔兹曼机的教程

Restricted Boltzmann Machines (computing in physics) 

t.cn/A6EjIxEq

## 3

继续说到Hinton获得诺贝尔物理学奖这件事情。

我向来重视将物理世界跟赛博世界联系起来看待问题，尤其是看待人工神经网络这一门技术。

不论是物理学还是信息通信，归根结底都是为了预测未来、解决问题。物质信息能量紧密耦合在一起，诸如所谓的兰道尔原理试图将他们归于一统。物理学研究信息的载体，力学研究载体的运动规律，而载体的运动规律某种意义上就是信息本身。物理学、力学和信息通信技术原本就应该是密不可分的。

而机器学习体现出一种尊重事实的、与时俱进的、后验修正先验的、积极进化的、闭环的认识论观点，人工神经网络将这种认识论观点推向极致。人工神经网络既是物理学的研究对象，也可以成为物理学乃至一切科学的研究工具。人工神经网络是自冯·诺依曼-图灵计算机之后的又一个里程碑的信息处理通用模型，它们的重要性就在于能够实现研究对象和研究手段的自举，bootstrapping，踩着自己的脚，让自己飞起来。能够自举的范式，必将成为人类文明群山当中的一座显著的高峰。

至于我自己对于人工神经网络的态度，也经历了十分戏剧性的转变。毕竟，去年的这个时候，我还埋头于数理逻辑和哥德尔不完全性定理当中无法自拔。

