# 2025-10-19

## 1

在什么情况下会得罪小人

海上一浪花

我们通常认为：如果我冒犯了谁，说了谁的坏话，阻碍了谁的事情，就会得罪这个人。这是常理，但并不是所有人都遵循常理，有一些人，你没有冒犯他，也没说他坏话阻碍他事情，仅仅是正常对待他，也会不知不觉地得罪他。

举几个例子说说大明朝的几件事。

武宗朱厚照时期，锦衣卫左都督钱宁非常受宠，权势熏天。他替宁王朱宸濠拉拢朝中重臣，主动结交当时的阁臣费宏，就送他珍玩宝贝。费宏是个正直的人，觉得这样不合适，就没收。不收礼这个举动，就得罪了送礼的人，钱宁和朱宸濠认为费宏不收自己的礼，是看不起自己，不想跟自己站在一头，从此记恨上了费宏，派人暗中收集费的各种失误，最终把费宏挤兑得告老还乡。就这样，钱宁还没觉得出气，在费宏还乡路上派人烧了他乘坐的船，家当全毁于火中。

英宗朱祁镇时期，大太监王振当权的时候，对别人对他尊敬不尊敬特别看重，俗话说自己光头怕人提秃子，就是这种心态。大理府少卿薛瑄有一次见王振，王上前作揖，薛瑄没有还礼，为这事，王振之后找他的茬，差点把薛瑄害死。驸马都尉石燝在家里骂自己家的阉人家丁，被王振知道了，王也认为他是拐着弯的骂自己，收集石燝的过失把他下狱。

熹宗朱由校时期，大太监魏忠贤在这个问题上就更明显了。他当上司礼监掌印太监，是比较心虚的，因为司礼监掌印太监职责上是为皇帝批答诏书的，要识文断字才行，而魏忠贤根本不认字。虽然他通过找人帮忙念文件等方式弥补了这个缺陷，但这事始终是他的一个心结。有一次，吏部郎中周顺昌说魏忠贤“目不识丁”，由此犯了魏的大忌。魏忠贤兴起大狱，将因各种事得罪他的周顺昌等人虐待至死。周临死前，被魏的爪牙用沸水浇身、铁钉钉身，痛苦到无法说话时，监刑者还问：“此时你还敢说魏公不识一丁吗？！”可见魏忠贤对这样一句评价有多衔恨。

得罪小人，常常在不经意之间。而被小人陷害，也常是懵懵懂懂中就中招了。英宗朱祁镇复辟后，帮他复辟的大臣徐有贞当上了首辅，总揽朝廷事权，英宗也很信任他。但他自己不知道自己得罪了太监曹吉祥，曹躲在暗处处心积虑地想辙害他。有一次英宗屏退左右，与徐有贞私密谈国事，曹令小宦官躲在一边偷听两人谈话，之后的某一天，装作若无其事地跟朱祁镇讲起谈话中的内容。朱祁镇大惊，问“你怎么知道的？”曹吉祥说“是徐有贞告诉我的。”朱祁镇当时就对徐有贞产生了怀疑，此后即疏远了他。而这前前后后诸般情形，徐有贞始终不明就里。最终，英宗将徐有贞贬为庶民，流徙金齿（在今云南）。`历史上的浪花##微博兴趣创作计划`

## 2

`模型时代` Andrej Karpathy最新访谈：我们没有在制造生灵，而是在召唤幽灵

Andrej Karpathy这次在Dwarkesh Patel的访谈必然是要引起轰动的，刚看了一下，不到一天已经16万次观看。Andrej Karpathy的资历不用说了，15年原生AI研究、曾任Tesla自动驾驶负责人，还是OpenAI创始成员的技术大牛。

标题是我意译的，原文是： “We’re summoning ghosts, not building animals”

这期播客，他分享了他对AGI时间线、强化学习陷阱、以及AI教育革命的独特见解。当然，最引发关注的，还是他对强化学习的看法。

前不久，Sutton做了一系列访谈，讲了强化学习是AGI必由之路，而Andrej Kaparthy的看法则显然不同。我简单做了归纳：

分歧一：对强化学习本质价值的判断截然相反

Sutton认为强化学习是"基础AI"，是智能的核心和本质。他主张智能就是从真实经验中学习、通过奖励信号来判断行为好坏，这才是理解世界的正确方法。

相反，Karpathy直言当前强化学习"糟糕透了"，批评其效率极低——让AI做几百次尝试，最后只能从"成功或失败"这一个信号来学习，就像"通过吸管吸取监督信号"。更糟的是，强化学习容易被钻空子：用大模型来评判AI的表现，结果AI学会了输出"dhdhdhdh"这样的乱码来骗取满分，因为这是评判模型没见过的、会判断错误的情况。

分歧二：对人类学习方式的理解完全不同

Sutton坚持人类和动物不是通过"老师示范、学生模仿"来学习的，而是通过试错来理解世界。他认为婴儿是自己尝试、自己发现规律的，自然界根本不存在有人手把手教的监督学习，"如果理解了松鼠的智能，就几乎理解了人类智能"。

Karpathy则持相反观点：人类很少用强化学习来学习智能任务，人类不会做几百次尝试然后根据最终成败简单地强化整个过程。人类会进行复杂的反思——"这一步我做对了，那一步做错了，下次应该这样"。而且人类有睡眠时的知识巩固、白天的工作记忆等机制，这些大模型都没有。

分歧三：对AI技术路线的选择根本对立

Sutton从基本原理出发，认为依赖人类知识的方法最终都会输给纯粹的"从经验学习+大算力"（这是他著名的"苦涩的教训"文章的核心）。他批评大语言模型只是在模仿人类说话，没有真正的目标，也没有对世界的真实理解。

Karpathy则是工程实用主义者，他认为让模型读遍互联网（预训练）虽然是"蹩脚的进化"，但这是现在能用的方法。他认为ChatGPT通过模仿人类对话微调出来是个惊人的成功。他主张当前应该走"大语言模型+改进的强化学习"路线，比如给学习过程的每一步打分、加入反思机制，而不是推倒重来。他直言："我是工程师，戴着安全帽，只关注什么真正管用。"

更多内容，就见下边的总结吧：

***

从"召唤幽灵"到"十年造神"：OpenAI前研究科学家Andrej Karpathy眼中的AGI真相

Andrej Karpathy，这位拥有15年AI研究经验、曾任Tesla自动驾驶负责人、OpenAI创始成员的技术大牛，在昨天发布的Dwarkesh Podcast分享了他对AGI时间线、强化学习陷阱、以及AI教育革命的独特见解。当所有人都在喊"2025是Agent元年"时，他冷静地说："这不是Agent的一年，这是Agent的十年。"

主体内容

一、AGI时间线：为什么是十年，不是一年？

第一性原理思考：Karpathy认为当前AI Agent就像一个"不太靠谱的实习生"，你想让它帮忙，但它就是做不到，主要原因包括智能不足、多模态能力欠缺、无法持续学习、缺乏计算机操作能力，这些认知缺陷需要至少十年时间逐一攻克。

"We're summoning ghosts, not building animals" - 这是Karpathy对当前AI本质的精准描述。LLM更像是在"召唤"知识的幽灵，而不是像动物那样真正理解和学习世界，它们在互联网文本中"发现"数学和推理，就像考古学家挖掘化石一样，但这种发现有其极限。

具体的认知缺陷包括：

• 无法进行符号运算：给LLM一个20位数乘法，它会完全崩溃，因为互联网上没有这样的例子，它无法像人类那样通过算法步骤进行计算

• 缺乏系统2思考：人类可以花10分钟思考一个问题，而LLM只能进行固定计算量的"快思考"，无法像AlphaGo那样通过搜索树进行深度推理

• 没有持续学习能力：告诉它一个事实，下次对话它就忘了，无法像人类那样积累经验

二、强化学习的陷阱：整个行业的集体误判

一个大胆的判断："强化学习很糟糕，但其他所有方法更糟糕。" Karpathy直言不讳地指出，2013-2017年整个AI界对强化学习游戏的痴迷是一个"misstep"（误入歧途），包括早期OpenAI在内的顶级实验室都在这条错误的道路上浪费了大量时间。

为什么强化学习不work：

• 奖励信号太稀疏：在Atari游戏中随机按键很难获得奖励，学习效率极低，就像在黑暗中摸索，可能要"烧掉一片森林的计算资源"也学不到什么

• 缺少表征能力：没有预训练的语言模型做基础，纯粹的强化学习就像让婴儿直接学微积分

• 环境不真实：游戏世界太简单，无法迁移到真实世界的复杂任务

正确的路径：先通过大规模预训练获得强大的表征能力（LLM），再在上面构建Agent能力，这就是为什么现在的computer-use agents都建立在LLM基础上。

三、人类学习 vs AI学习：两条完全不同的路

关键洞察：人类和AI的学习机制完全不同，试图让AI模仿人类学习是错误的方向，人类从少量数据中学习是因为有亿万年进化赋予的先验知识，而AI必须从海量数据中重新发现这些规律。

人类学习的秘密：

• 进化的礼物：人类大脑是40亿年进化的产物，携带着巨量的先验知识，一个婴儿的大脑已经"知道"很多关于物理世界的规律

• 文化传承：25万年的文化积累让每个人站在巨人的肩膀上，语言、工具、知识体系都是压缩后的智慧传承

• 效率极高：正因为有这些基础，人类才能从少量样本中快速学习

AI的不同路径：

• 从零开始：LLM必须从原始数据中重新发现所有规律，就像重新进化一遍

• 规模优势：但AI可以同时处理海量数据，不受人类认知带宽限制

• 新的可能：这种不同可能让AI发现人类从未注意到的模式

四、AGI的经济影响：融入2%的GDP增长曲线

反直觉的预测：AGI不会带来经济奇点或爆炸式增长，而是会自然融入过去250年来稳定的2%人均GDP增长曲线，就像工业革命、电力、互联网一样，成为推动经济增长的又一个重要因素。

为什么不会有奇点：

• 物理世界的约束：经济增长最终受限于原子世界的物理规律，建工厂、造房子、运输货物都需要时间

• 人类需求的限制：人的需求增长是有限的，不会因为AI变强而突然想要100倍的商品

• 系统的惯性：经济系统有巨大惯性，新技术需要时间渗透到各个行业

真实的影响模式：

• AI会像之前的通用技术一样，逐步提高各行业生产力，但这种提升会被市场机制消化，体现为缓慢而稳定的增长

• 最大的变化可能是工作性质的转变，而不是财富的爆炸式增长

五、自动驾驶为什么这么难：Tesla经验的深刻教训

核心问题：自动驾驶之所以困难，不是因为驾驶本身很难，而是因为要处理无数的"长尾问题"（edge cases），真实世界的复杂性远超想象。

Tesla的进化历程：

• 第一代：基于规则的系统，工程师手写代码处理各种情况

• 第二代：深度学习接管感知，但决策仍基于规则

• 第三代：端到端神经网络，从传感器到控制全部由AI完成

为什么端到端才是正解：

• 人类驾驶是端到端的：看到情况→大脑处理→输出动作，中间没有"车道线检测""物体分类"等中间步骤

• 分模块系统的问题：信息在模块间传递会丢失，错误会累积，无法处理未预见的情况

• 端到端的优势：可以学习隐含的模式，自动优化整体性能，而不是局部最优

六、教育的未来：从"知识传递"到"智慧引导"

Karpathy的教育哲学："教育是最有智力挑战的任务，因为你要把纠缠的知识解开，排列成一个坡道，让每一步只依赖前一步。"

优秀教育的要素：

• 激发动机：先展示痛点，再给出解决方案，让学习者理解"为什么需要这个知识"

• 循序渐进：从lookup table到transformer，每一步都有充分的动机，像从bigram开始教transformer，先用最简单的查找表，然后逐步添加复杂性

• 主动参与：在给出答案前让学习者先尝试，这样他们才能真正理解解决方案的价值

知识的诅咒：专家很难教好初学者，因为他们已经内化了太多"显而易见"的东西，解决方法是看初学者和ChatGPT的对话，了解他们真正的困惑点。

未来教育的形态：

• AI tutor将提供个性化教育，根据每个人的理解程度调整教学节奏

• 但人类教师仍然重要，因为教育不只是知识传递，还包括动机激发、情感支持、品格塑造

总结

Andrej Karpathy的核心观点是：我们不应该试图复制人类智能，而应该理解AI的独特路径。当前的LLM像是在"召唤"互联网知识的幽灵，而不是真正理解世界。通向AGI的路还很长，需要十年时间解决持续学习、多模态理解、系统性推理等根本问题。

但这不是悲观的预测，而是理性的规划。就像自动驾驶从规则系统evolve到端到端神经网络花了十年，AGI的实现也需要时间。而当它真正到来时，不会是科幻电影中的奇点爆炸，而是像历次工业革命一样，悄然融入人类文明的进步曲线。

最重要的是，我们需要重新思考教育。在AI时代，知识获取变得简单，但理解和创造仍然困难。未来的教育应该像Karpathy的课程一样，不是灌输事实，而是培养思考的方法。

QA：三个最核心的洞察

Q：为什么说当前的AI是在"召唤幽灵"而不是"构建动物"？  

A：LLM的本质是在互联网文本中"发现"已存在的模式，就像考古学家挖掘化石。它们能够重现人类知识，但缺乏动物那样的主动学习和适应能力。一个20位数的乘法就能让最强大的LLM崩溃，因为互联网上没有这样的例子，而一个小学生通过算法就能解决。这揭示了当前AI的根本局限：它们是知识的搬运工，而不是智慧的创造者。

Q：为什么强化学习这条路走不通，整个行业都判断错了？  

A：2013-2017年，包括OpenAI在内的顶级实验室都在用强化学习玩Atari游戏，希望通过这条路通向AGI。但Karpathy认为这是collective misstep，原因是强化学习就像让婴儿直接学微积分——没有基础表征能力，光靠试错永远学不会复杂任务。正确的路径是先通过大规模预训练获得语言理解能力（LLM），再在此基础上构建Agent。这个教训告诉我们：在AI发展中，顺序比努力更重要。

Q：AGI真的会带来经济奇点吗？  

A：不会。Karpathy给出了反直觉但compelling的论证：过去250年，尽管有蒸汽机、电力、计算机等革命性技术，人均GDP增长始终稳定在2%左右。AGI也会遵循这个规律，因为经济增长最终受限于物理世界和人类需求。你不会因为AI变强就突然想要100倍的食物或衣服。AGI的真正影响不是财富爆炸，而是工作性质的根本改变——就像农民变成了程序员一样，我们都会找到新的创造价值的方式。 http://t.cn/AXw4fcbd

## 3

最近儿子在学水管问题

没错，就是之前某专家喷的，活了84岁，没见过一边注水一边放水的，属于脑子有病，文盲变戏法～

且不说这类题目旨在在训练数学思维，咱就说，一边注水一边放水，难道生活中不是很多例子吗？

比如图1，我儿子正在做的题，就是一个水库，上游洪水不断流入，需要计算同时打开几个泄洪闸，这难道不是很实用吗？

生活中例子就更多了，比如库存管理，库存一边消耗、一边补充，我们需要决策库存补充速度。

再比如，外循环游泳池，就是一边注水一边放水，排出的水过滤后重新注入，从而保持泳池清洁

有些人，真是批评都批不到点子上～

`海豚育儿系列`

## 4

封面新闻的这个报道，基本已经把跳河自杀的原因，都写出来了。

大家可以仔细看一下报道内容。

男方在订婚时给了13.6万的彩礼、金饰等花费近20万，但两年来女方多次推迟结婚，并且到了结婚阶段，女方要求提前敬酒、接亲礼品数量、下车费等，男方实在承受不住，可能在精神层面也遭受了很大打击，最后选择自杀。

案发后，当地官方先是直接否定因为彩礼原因，导致的自杀，并且开始辟谣。不但辟谣，还开始抓谣言。官方不给你真相，舆论报道躲躲藏藏，让你无法获得准确消息，但谁要是忍不住传播，并在传播的过程中，描述的跟事实有偏差，便可能会被认定为是谣言。

轻则被行政拘留，重则被刑事拘留。

所以大家看哈，虽然法律层面明确规定禁止借婚姻索取财物，国家政策层面多次表示，要遏制高额彩礼，但是到了实操层面，是非不分。

明明这样的案例，是打击借婚姻索取财物、遏制高额彩礼的极佳案例，但是到了执行层面，不但不宣传、不贯彻、不执行，反而搞到风声鹤唳。

这么搞的话，如果官方以后再出台禁止借婚姻索取财物、遏制高额彩礼的法律规定或政策，谁还愿意信？这不是把大家伙当猴耍么？`婚俗争执成压垮新郎最后稻草##热点观点`

## 5

企业守住现金生命的三大铁律：

1、把应收账款当"敌人"来管：每个滞压的应收账款都是抽走血液的血栓。建立严格的信用管理制度，宁可少做生意，不做烂生意。

2、视库存为"成本黑洞"：压在仓库里的每件货，都是被冻结的鲜血。京东为什么能碾压传统零售商？关键是库存周转天数只有31天。

3、用现金流指标考核团队：放弃单纯追求销售额和利润的考核方式，引入"经营活动现金流净额"这个核心指标。经手的项目必须带血（现金）回来。

## 6

`模型时代` Andrej Karpathy最新访谈：我们没有在制造生灵，而是在召唤幽灵

Andrej Karpathy这次在Dwarkesh Patel的访谈必然是要引起轰动的，刚看了一下，不到一天已经16万次观看。Andrej Karpathy的资历不用说了，15年原生AI研究、曾任Tesla自动驾驶负责人，还是OpenAI创始成员的技术大牛。

标题是我意译的，原文是： “We’re summoning ghosts, not building animals”

这期播客，他分享了他对AGI时间线、强化学习陷阱、以及AI教育革命的独特见解。当然，最引发关注的，还是他对强化学习的看法。

前不久，Sutton做了一系列访谈，讲了强化学习是AGI必由之路，而Andrej Kaparthy的看法则显然不同。我简单做了归纳：

分歧一：对强化学习本质价值的判断截然相反

Sutton认为强化学习是"基础AI"，是智能的核心和本质。他主张智能就是从真实经验中学习、通过奖励信号来判断行为好坏，这才是理解世界的正确方法。

相反，Karpathy直言当前强化学习"糟糕透了"，批评其效率极低——让AI做几百次尝试，最后只能从"成功或失败"这一个信号来学习，就像"通过吸管吸取监督信号"。更糟的是，强化学习容易被钻空子：用大模型来评判AI的表现，结果AI学会了输出"dhdhdhdh"这样的乱码来骗取满分，因为这是评判模型没见过的、会判断错误的情况。

分歧二：对人类学习方式的理解完全不同

Sutton坚持人类和动物不是通过"老师示范、学生模仿"来学习的，而是通过试错来理解世界。他认为婴儿是自己尝试、自己发现规律的，自然界根本不存在有人手把手教的监督学习，"如果理解了松鼠的智能，就几乎理解了人类智能"。

Karpathy则持相反观点：人类很少用强化学习来学习智能任务，人类不会做几百次尝试然后根据最终成败简单地强化整个过程。人类会进行复杂的反思——"这一步我做对了，那一步做错了，下次应该这样"。而且人类有睡眠时的知识巩固、白天的工作记忆等机制，这些大模型都没有。

分歧三：对AI技术路线的选择根本对立

Sutton从基本原理出发，认为依赖人类知识的方法最终都会输给纯粹的"从经验学习+大算力"（这是他著名的"苦涩的教训"文章的核心）。他批评大语言模型只是在模仿人类说话，没有真正的目标，也没有对世界的真实理解。

Karpathy则是工程实用主义者，他认为让模型读遍互联网（预训练）虽然是"蹩脚的进化"，但这是现在能用的方法。他认为ChatGPT通过模仿人类对话微调出来是个惊人的成功。他主张当前应该走"大语言模型+改进的强化学习"路线，比如给学习过程的每一步打分、加入反思机制，而不是推倒重来。他直言："我是工程师，戴着安全帽，只关注什么真正管用。"

更多内容，就见下边的总结吧：

***

从"召唤幽灵"到"十年造神"：OpenAI前研究科学家Andrej Karpathy眼中的AGI真相

Andrej Karpathy，这位拥有15年AI研究经验、曾任Tesla自动驾驶负责人、OpenAI创始成员的技术大牛，在昨天发布的Dwarkesh Podcast分享了他对AGI时间线、强化学习陷阱、以及AI教育革命的独特见解。当所有人都在喊"2025是Agent元年"时，他冷静地说："这不是Agent的一年，这是Agent的十年。"

主体内容

一、AGI时间线：为什么是十年，不是一年？

第一性原理思考：Karpathy认为当前AI Agent就像一个"不太靠谱的实习生"，你想让它帮忙，但它就是做不到，主要原因包括智能不足、多模态能力欠缺、无法持续学习、缺乏计算机操作能力，这些认知缺陷需要至少十年时间逐一攻克。

"We're summoning ghosts, not building animals" - 这是Karpathy对当前AI本质的精准描述。LLM更像是在"召唤"知识的幽灵，而不是像动物那样真正理解和学习世界，它们在互联网文本中"发现"数学和推理，就像考古学家挖掘化石一样，但这种发现有其极限。

具体的认知缺陷包括：

• 无法进行符号运算：给LLM一个20位数乘法，它会完全崩溃，因为互联网上没有这样的例子，它无法像人类那样通过算法步骤进行计算

• 缺乏系统2思考：人类可以花10分钟思考一个问题，而LLM只能进行固定计算量的"快思考"，无法像AlphaGo那样通过搜索树进行深度推理

• 没有持续学习能力：告诉它一个事实，下次对话它就忘了，无法像人类那样积累经验

二、强化学习的陷阱：整个行业的集体误判

一个大胆的判断："强化学习很糟糕，但其他所有方法更糟糕。" Karpathy直言不讳地指出，2013-2017年整个AI界对强化学习游戏的痴迷是一个"misstep"（误入歧途），包括早期OpenAI在内的顶级实验室都在这条错误的道路上浪费了大量时间。

为什么强化学习不work：

• 奖励信号太稀疏：在Atari游戏中随机按键很难获得奖励，学习效率极低，就像在黑暗中摸索，可能要"烧掉一片森林的计算资源"也学不到什么

• 缺少表征能力：没有预训练的语言模型做基础，纯粹的强化学习就像让婴儿直接学微积分

• 环境不真实：游戏世界太简单，无法迁移到真实世界的复杂任务

正确的路径：先通过大规模预训练获得强大的表征能力（LLM），再在上面构建Agent能力，这就是为什么现在的computer-use agents都建立在LLM基础上。

三、人类学习 vs AI学习：两条完全不同的路

关键洞察：人类和AI的学习机制完全不同，试图让AI模仿人类学习是错误的方向，人类从少量数据中学习是因为有亿万年进化赋予的先验知识，而AI必须从海量数据中重新发现这些规律。

人类学习的秘密：

• 进化的礼物：人类大脑是40亿年进化的产物，携带着巨量的先验知识，一个婴儿的大脑已经"知道"很多关于物理世界的规律

• 文化传承：25万年的文化积累让每个人站在巨人的肩膀上，语言、工具、知识体系都是压缩后的智慧传承

• 效率极高：正因为有这些基础，人类才能从少量样本中快速学习

AI的不同路径：

• 从零开始：LLM必须从原始数据中重新发现所有规律，就像重新进化一遍

• 规模优势：但AI可以同时处理海量数据，不受人类认知带宽限制

• 新的可能：这种不同可能让AI发现人类从未注意到的模式

四、AGI的经济影响：融入2%的GDP增长曲线

反直觉的预测：AGI不会带来经济奇点或爆炸式增长，而是会自然融入过去250年来稳定的2%人均GDP增长曲线，就像工业革命、电力、互联网一样，成为推动经济增长的又一个重要因素。

为什么不会有奇点：

• 物理世界的约束：经济增长最终受限于原子世界的物理规律，建工厂、造房子、运输货物都需要时间

• 人类需求的限制：人的需求增长是有限的，不会因为AI变强而突然想要100倍的商品

• 系统的惯性：经济系统有巨大惯性，新技术需要时间渗透到各个行业

真实的影响模式：

• AI会像之前的通用技术一样，逐步提高各行业生产力，但这种提升会被市场机制消化，体现为缓慢而稳定的增长

• 最大的变化可能是工作性质的转变，而不是财富的爆炸式增长

五、自动驾驶为什么这么难：Tesla经验的深刻教训

核心问题：自动驾驶之所以困难，不是因为驾驶本身很难，而是因为要处理无数的"长尾问题"（edge cases），真实世界的复杂性远超想象。

Tesla的进化历程：

• 第一代：基于规则的系统，工程师手写代码处理各种情况

• 第二代：深度学习接管感知，但决策仍基于规则

• 第三代：端到端神经网络，从传感器到控制全部由AI完成

为什么端到端才是正解：

• 人类驾驶是端到端的：看到情况→大脑处理→输出动作，中间没有"车道线检测""物体分类"等中间步骤

• 分模块系统的问题：信息在模块间传递会丢失，错误会累积，无法处理未预见的情况

• 端到端的优势：可以学习隐含的模式，自动优化整体性能，而不是局部最优

六、教育的未来：从"知识传递"到"智慧引导"

Karpathy的教育哲学："教育是最有智力挑战的任务，因为你要把纠缠的知识解开，排列成一个坡道，让每一步只依赖前一步。"

优秀教育的要素：

• 激发动机：先展示痛点，再给出解决方案，让学习者理解"为什么需要这个知识"

• 循序渐进：从lookup table到transformer，每一步都有充分的动机，像从bigram开始教transformer，先用最简单的查找表，然后逐步添加复杂性

• 主动参与：在给出答案前让学习者先尝试，这样他们才能真正理解解决方案的价值

知识的诅咒：专家很难教好初学者，因为他们已经内化了太多"显而易见"的东西，解决方法是看初学者和ChatGPT的对话，了解他们真正的困惑点。

未来教育的形态：

• AI tutor将提供个性化教育，根据每个人的理解程度调整教学节奏

• 但人类教师仍然重要，因为教育不只是知识传递，还包括动机激发、情感支持、品格塑造

总结

Andrej Karpathy的核心观点是：我们不应该试图复制人类智能，而应该理解AI的独特路径。当前的LLM像是在"召唤"互联网知识的幽灵，而不是真正理解世界。通向AGI的路还很长，需要十年时间解决持续学习、多模态理解、系统性推理等根本问题。

但这不是悲观的预测，而是理性的规划。就像自动驾驶从规则系统evolve到端到端神经网络花了十年，AGI的实现也需要时间。而当它真正到来时，不会是科幻电影中的奇点爆炸，而是像历次工业革命一样，悄然融入人类文明的进步曲线。

最重要的是，我们需要重新思考教育。在AI时代，知识获取变得简单，但理解和创造仍然困难。未来的教育应该像Karpathy的课程一样，不是灌输事实，而是培养思考的方法。

QA：三个最核心的洞察

Q：为什么说当前的AI是在"召唤幽灵"而不是"构建动物"？  

A：LLM的本质是在互联网文本中"发现"已存在的模式，就像考古学家挖掘化石。它们能够重现人类知识，但缺乏动物那样的主动学习和适应能力。一个20位数的乘法就能让最强大的LLM崩溃，因为互联网上没有这样的例子，而一个小学生通过算法就能解决。这揭示了当前AI的根本局限：它们是知识的搬运工，而不是智慧的创造者。

Q：为什么强化学习这条路走不通，整个行业都判断错了？  

A：2013-2017年，包括OpenAI在内的顶级实验室都在用强化学习玩Atari游戏，希望通过这条路通向AGI。但Karpathy认为这是collective misstep，原因是强化学习就像让婴儿直接学微积分——没有基础表征能力，光靠试错永远学不会复杂任务。正确的路径是先通过大规模预训练获得语言理解能力（LLM），再在此基础上构建Agent。这个教训告诉我们：在AI发展中，顺序比努力更重要。

Q：AGI真的会带来经济奇点吗？  

A：不会。Karpathy给出了反直觉但compelling的论证：过去250年，尽管有蒸汽机、电力、计算机等革命性技术，人均GDP增长始终稳定在2%左右。AGI也会遵循这个规律，因为经济增长最终受限于物理世界和人类需求。你不会因为AI变强就突然想要100倍的食物或衣服。AGI的真正影响不是财富爆炸，而是工作性质的根本改变——就像农民变成了程序员一样，我们都会找到新的创造价值的方式。 http://t.cn/AXw4fcbd

## 7

这是我今年看过最好的文章

~~~~~~~~~

今天我一边泡澡，一边想到一个深刻的问题

为什么人的生命中最有价值的东西都很便宜，而贵的东西往往价值约等于零

便利店一瓶水2块钱。Tiffany一枚钻戒28万。

如果此刻我脱水濒死，给我100颗钻石我也不会要，我只要那瓶水（在我不得不喝自己的洗澡水之前）。但为什么我们的一生，都在追逐钻石，却对水的重要性定价那么低？

我觉得这不简单是个关于消费主义的陈词滥调。这是一个关于人们如何被劫持的故事。

其实亚当·斯密在1776年就看穿了这个水与钻的悖论。

对生命至关重要的水（哦，还有空气），几乎免费；

对生存毫无用处的钻石，价值连城。

经济学解释很简单：价格反映的不是"总体重要性"，而是"边际效用"和"稀缺程度"。

但这个合理的定价机制，在心理层面给人们下了一个诅咒。

人们开始把"价格高"误读为"更重要"。

更可怕的是，人类的大脑天生就是这个骗局的帮凶。

神经科学家发现，人类的多巴胺系统对"意外之喜"和"稀缺信号"反应剧烈，但对那些稳定、持续的好处，比如健康、亲密关系、安全感，它会迅速"适应"，调低音量，甚至彻底静音。

于是一个荒诞的现象出现了，

一条"限量发售"的推送能让你心跳加速，

但一个家人的拥抱、一次日落、一杯干净的空气，在你的情绪仪表盘上激不起任何波澜。

商业世界精准捕捉了这个漏洞，并将其工程化，

所有的"限量""联名""仅剩3件""今日特惠"，都是在利用你对稀缺的原始恐慌，抬高你的心理估值。

而那句"钻石恒久远，一颗永流传"，更是把一块碳元素（对就是跟铅笔芯同类的）包装成了爱情的终极证明。

人们购买的早已不是物品本身，而是它所承载的叙事、符号和地位信号。

但这场由经济逻辑、神经漏洞和商业叙事共同导演的"稀缺狂欢"里，大家到底失去了什么？

哈佛大学有一项持续了86年的研究，追踪了700多个人的完整人生。这可能是人类历史上关于幸福最严肃的一次追问。

结论震撼又简单，

预测你晚年是否幸福、健康、长寿的最强指标，不是财富，不是名望，不是基因，而是50岁时你拥有的高质量人际关系。

那些真正滋养生命的东西，恰恰是充沛的、可得的、甚至免费的。

临终的病床上没人会遗憾

“哎呀我人生没有挎过爱马仕”，

而是

“如果之前能多花点时间跟孩子在一起多好”，

“上了天能不能重回妈妈的怀抱，就像小时候一样”

另一个实验中，研究者让人们选择用文字还是语音联系久未谋面的朋友。几乎所有人都选择了文字，因为觉得打电话"尴尬""冒昧"。但当他们真的拨通电话后，连接感是文字的数倍，而对方感受到的温暖也远超他们的预期。

人们系统性地低估了那些简单、直接、人性化的连接的力量。

更讽刺的是那些对人类文明最有价值的资源，本质上都是"反稀缺"的。

知识不会因为被分享而减少，反而会因为传播而增值。MIT，斯坦福都在把课程免费开放。

这些顶尖智慧本可以标价百万，但他们选择了"零价格"。

因为知识、思想、语言这些东西，价值在于点燃，在于共鸣，而不是独占。它们越被使用，就越丰盈。

互联网本应是这种丰盈的放大器，但人们却用它制造了新的稀缺游戏。大家耗费巨量的时间、金钱和注意力，追逐那些被标为"稀缺"的符号；却对那些真正让我们活过来的、充沛的连接与意义，视而不见。

并没有号召大家放弃消费过上苦行僧生活的意思。

只是，也许，

需要在心里建立两本账。

第一本是"价格账"，用来处理外部世界，比较性价比，购买效率工具。这本账很重要。

第二本是"价值账"，用来关照内心世界。这本账只问一个问题： 这件事是不是然我发自内心地感到快乐？

如果用"价值账"重新计算，会发现很多东西的权重发生了惊人的倒转。

一个限量版包包，在价格账上价值两万，在价值账上可能只值2块。 一通给初恋情人的十分钟电话，在价格账上接近于零，在价值账上可能值20万。

这不是反消费，而是把消费从人生的主角降为配角。

把最宝贵的注意力（这个时代真正的稀缺品）优先分配给那些在"价值账"上有分量的事情。

生活是否丰盛，不取决于拥有多少"昂贵"的东西，而取决于有多少"便宜"甚至"免费"的东西在心里开始变得有分量。

那瓶2块钱的水和那枚28万的钻戒，哪个更重要？

也许你的身体早就知道答案。

只是你的大脑，还在犹豫。

最后，如果你读到这里我这篇价格为零的随笔，觉得有点感触的价值，也算印证了一点我的想法。

谢谢。

## 8

//@CC女士不是西西:今天刚听完杨振宁先生的讲座，现炒现卖一下他分享的教育和学习观点：1）我们的直觉经常和书本知识相冲突，必须抓住这种最好的学习机会，因为学习就是持续不断的对自己的直觉进行再修正；2）西方物理学教育推崇归纳法，即教育学生如何从观察到的（新）现象得出（新）理论；而中国的物理学教育推崇推演法，即教育学生如何从已确立的理论到现象；显然杨振宁先生更推崇西方的物理学教育方式。杨振宁先生分享的这种由好奇心和洞察驱使的探索性学习可能是人类最高级的学习方式了，无论前沿科学发现还是技术应用创新，都依赖于这种方式。而规则明确的强化学习，例如AlphaGo Zero，则可以理解为是一种推演法，只不过AI的搜索和推演空间远强于我们人类大脑。死记硬背和对应的考试模式，是最常见的强化学习模式，但是人类更高级的学习奖励，其影响远比强化学习的奖励来的要持久、深远和强烈。

## 9

杨振宁获得1957年诺贝尔奖的那个成果，宇称不守恒，只是他学术生涯的开始。

就像爱因斯坦获得诺贝尔物理学家，是靠光电效应。

光电效应和相对论相比，实在太过于微不足道了。

但是相对论实在太过于逆天和反直觉，当时还没有被证实，但是物理学家们认为大概率是对的。

那么怎么办呢？

不给爱因斯坦颁奖，那就错过了一个大师，颁奖的话，万一被证明是错的，就尴尬了。

就给他用光电效应来颁奖。

你看，老外也是会权变的。

杨振宁的成果，也大概如此。

宇称不守恒当然可以获得诺贝尔奖，但是这个成果在杨振宁的贡献中份量只是中等。

其实他最重要的贡献，是杨-米尔斯场，杨-巴斯克方程等等。

这些贡献，就像一只鸟，飞过雨林，看清了物理学的基本脉络，只是细节尚不清楚。

这个不好颁奖，否则，可以再次获得诺贝尔奖。

在1999年的物理学的会议中，杨振宁是站C位的。

就像爱因斯坦在索维尔会议中站C位一样。

这就是杨振宁在物理学的地位。

杨振宁在是冷战后首次访华的物理学家，后面也资助很多年轻学者去美国留学。

这些学者在中国的科学和工程技术方面发挥了重要作用。

杨振宁这种级别，在美国一样可以有很好的条件养老。

他能回国，对国内的贡献很大。

说白了，虽然成为了顶级的学者，还是一个典型的，有家国情怀的中国人。

## 10

杨振宁先生一生总有三个绕不开的争议

1.是为什么没在最困难的时候建设祖国

杨以前的身份比较敏感，作为国民党高级军官（“战犯“杜聿明）的女婿，很有可能受到波及。(当然我党还是对杜很好的，拿着金条给杜买进口药治病，所以才能通过杜联系上杨. 光头对杜全家太差了，整得杜的大儿子因为没钱交学费自杀了)

最重要的是，杨是理论物理学家，在我国一切都还刚刚起步的当时，他的研究毫无用武之地。同样的，当时我们国家也根本没有办法给他提供研究理论物理的设备和环境。

接下来说第二点，【杨是贪图安逸享乐才回归祖国，而且还对祖国毫无贡献吗】？

我们就暂且不说，杨的理论对整个人类的贡献有多大，而某些人居然把单单把中国给摘出去是有多可笑了。

就来说一些实打实的，只对中国的贡献。

杨振宁入美国籍之后，继续给中国做贡献，比如参加了第一次保钓运动，为此还以诺奖得主身份上了美国的国会听证会。

中美关系刚刚解冻，第一时间回国，把好兄弟邓稼先从牛棚捞了出来。

作为桥梁，推动了一系列中美科技交流活动，催生了建国后第一批学术留学，还帮中国科学界弄回来了一堆钱。

全职回国之后， 为了在国内开学术会议，咖啡壶都是拿的自家的东西。

重建了清华物理系，为了筹钱，连自家纽约的房子都卖了捐了。

最终加入中国籍，并且拐回来了姚期智。

这是什么？这是拿着美国的钱，帮中国办事，最后深海成功归队。

杨先生人生分为三个阶段。

1，以中国人的身份，做了杨米尔斯规范场论，拿了诺贝尔奖，给中国人争了光。

2，以美国人的身份，向中国输送了无数不可替代的资源。

3，重回中国人身份，拐回来一个姚期智。

最后说一个让我觉得很不解的事，其实很多科学家都有类似杨振宁这样的私生活的新闻，我觉得当作逸闻，八卦未尝不可。但是，其实其中很多都没有被证实的，我们也永远不可能知道这些伟人们的所谓“人品”到底是好是坏，而这些科学家们的贡献却是实实在在让我们每个人都受益的，有些人居然会因为前者而无视后者。真的让我觉得非常不可思议。

## 11

爱因斯坦找到相对论并不是因为迈克尔逊莫雷实验，实际上他不知道这个时间，他单纯是为了解决麦克斯韦方程不满足伽利略变换的问题，提出洛伦兹变换和狭义相对论。

重大的科学进步都来自于死磕绝大多数人接受的矛盾现象上。

++++

香农有一个信息论中对信息量的定义，柯尔莫哥洛夫对算法有另一个，两者「显然」不是一回事而且后面这个不是那么令人满意，它更像一个工程定义而不是科学定义，是缺乏杨振宁先生说的那种taste的。

你要是能解决这个问题，你很可能可以拿一个诺贝尔物理学奖而不是图灵奖。

++++

维特根斯坦「哲学研究」123节，扣特，

德语原文

Der philosophische Problem hat die Form: Ich kann mich nicht orientieren.

Anscombe的英译

The philosophical problem has the form: 'I don't know my way about.'

陈嘉映的中译（从德文直译

哲学问题具有这样的形式：“我找不着北。”

## 12

哈佛大学的Introduction to Machine Learning Systems ↓

这是一本开源教材，旨在教你如何构建“真正可用的”机器学习系统（从模型训练到部署、运维、在边缘设备上的部署等）。 

它原来是哈佛大学的 CS249r 课程教材（由 Vijay Janapa Reddi 教授主导）演变而来，现在被许多学校与学习者在全球使用。 

它以“系统视角”为中心：不仅关注算法、模型本身，也重视数据管道、部署架构、监控、资源优化、边缘 AI 等环节。 

★ 亮点

1. 全栈覆盖

它不只是讲模型训练或深度学习，而是覆盖 ML 系统的完整链条：

（1）系统设计 —— 如何设计可扩展、可维护的机器学习架构 

（2）数据工程 —— 数据采集、标注、预处理、流水线管理 

（3）模型部署与监控 —— 将原型模型投入生产环境，并持续监控、纠偏 

（4）边缘 AI / 嵌入式部署 —— 资源受限设备上的高效执行 

2. 动手实验 / 实验室（Labs）支撑

教材中内嵌有实验室（labs）模块，让读者可以在动手实验中实际搭建系统，而不是仅停留在理论 

3. 现代工具链与自动化支撑

项目配备了 “Binder CLI”（一个命令行工具，用于快速构建、预览、部署书籍内容） 

构建流程支持输出 HTML、PDF、EPUB 等多种格式，且用 GitHub Actions 自动化部署 

5. 持续更新 & 版本计划

教材是活书（living book）：随着 ML 系统发展不断更新内容 

预计 2026 年将通过 MIT Press 出纸质版实体书 

访问：github.com/harvard-edge/cs249r_book

`人工智能##科技`

## 13

一个女生骂男生，往男生头上倒饮料，男生想还击，被另一个男生阻拦。

很多人骂那个出面阻拦的男生。

其实我倒觉得，他做的没错。

很多人对男女生理力量的差距之大，完全没有概念。

我这么说吧，一个暴怒女生给男生造成的伤害，充其量是挠几个口子。

而一旦男生情绪失控，在暴怒状态下攻击一名女生，如果没有和他力量差不多的同性及时阻拦，只要一分钟时间就可能会出人命。

除非真想找死，否则女生不要一对一和男生单挑，尤其不要刺激对方进入狂化状态。

这真不是开玩笑。

## 14

【`老旧小区自主更新实践及立法实操建议`】2025年8月28日发布的《中共中央国务院关于推动城市高质量发展的意见》明确提出，“稳步推进城中村和危旧房改造，支持老旧住房自主更新、原拆原建，持续推动城镇老旧小区改造”。老旧住房拆除式自主更新，被明确为今后城市更新的重要模式。 http://t.cn/AXwbWxvB

## 15

`日本前首相村山富市去世##村山富市曾为日本罪行道歉`

村山富市是个【务实】的日本政客。

村山富市很清楚「只有【忏悔二战时的日本罪行】才能让日本长期生存。日本只有长期生存下去才有可能会得到『争取到实现【日本利益最大化】的机会和时间』」。

村山富市明白高市早苗的做法会损害【日本的长期利益】。[吃瓜]

『村山富市的【务实】』是个很有意思的话题，所以，我多聊几句：

①村山富市在当众议院议员之前是【社会党左派】；

但是，村山富市在当了众议院议员以后就立刻转变成【社会党右派】了。[吃瓜]

②在【过去的一段时间】里，日本媒体为了图省事而管【反对“自社先联立政权”】的人叫“社会党右派”、管【支持“自社先联立政权”】的人叫“社会党左派”，

日本媒体的这个图省事的做法导致了『村山富市曾经被一部分人误会成了【社会党左派】』这个现象，

但是，村山富市一直坚称他自己是【社会党右派】。[吃瓜]

（注释：“自社先联立政权”就是自民党、社会党、先驱新党的联立政权。[吃瓜]）

③村山富市的政治态度是【支持社会民主主义，反社会主义】。[吃瓜]

④我很反对『网络左派简单粗暴地把村山富市说成【日本左翼/日本右翼】』，

因为事实是——『村山富市走的是【中道路线】。村山富市有时候是中道偏左、有时候是中道偏右』。[吃瓜]

村山富市反对【在天皇制下把政治大权集中于天皇一人】，但他不反【天皇制】本身。[吃瓜]

村山富市支持日美安保，

而且，村山富市干掉了「在【社会党内部】的『反安保；反美；反日本国旗，反日本国歌』这些左派势力」。[吃瓜]

村山富市是完全把日本左翼和日本右翼当成了『用来【实现日本利益最大化】的方式』，

所以，村山富市是个【务实】的日本政客。[吃瓜]

（注意：我的这篇微博不是在探讨【村山富市的对与错】。

我的这篇微博仅仅只是在探讨『村山富市的【务实】』。[吃瓜]）

## 16

在当今的世界，混的最惨的的人，一定是那些家境很差，自己又是循规蹈矩的那种人。

本身家境又差，还被规训得循规蹈矩，就像工厂批量制造出来的产品，没有差异化竞争力。

运气好点的，就是进了一个大厂，随着大平台的发展，吃一点红利。

等到年纪大了，被大厂毕业了，没有任何生存技能，不知道干什么，阶层再次滑落。

运气不好的，随波逐流，前怕狼后怕虎，越混越差。

我当然不是说让你去做刺头，偷奸耍滑，处处和人唱反调。

而是说，你要像乔布斯说的那样think different。

多想想不同的路子，可以多尝试一下，小成本的。

这些尝试未必能让你成功，所以一定要是小成本的。

你有了不同的人生体验，你才能与众不同，获得差异化竞争力。

