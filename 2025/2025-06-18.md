# 2025-06-18

## 1: 20250618-001705

伊朗的菜容易发现，以色列的菜你不好发现。

因为一直虐菜，没有露出马脚。

而且多年以来，感谢各种武侠小说和霸总文学式的传奇化，以色列国防军和摩萨德，是很多老登精神上给自己的犹太爷爷，“吹以色列等于吹美帝的爹，爹的爹行那我还能不行”。

以色列能在中东横行的根本原因，是中东地区只有它一个真正意义上的民族国家。War makes states and states make war。民族国家才能进行真正的现代战争动员。

而中东大部分国家没有东亚很常见的“政权，人民，版图”一体的国家观念。他们信奉的是“教派，强人，土地”，小共同体意识远大于国家意识。

而且长期的游牧部族历史，让土地这个概念和我们也不一样，这块土地养活我就是这块，另一块土地养活我就可以是另一块。

当然这是很多老登认为的比较高级的一种民族观念。他们自我意识就是换成这种游戏我肯定是手握弯刀的贵胄王公，怎么可能是部落仇杀的耗材呢？

而且他们也根本意识不到，基督教文明语境中的现代性必然意味着大屠杀。

“这片土地上的人配得上他们的苦难”，这是老登们挂在嘴边的一句话。实际上是中国人的大共同体意识真的是保护了太多巨婴，让他们能一直活到老登的年纪。而不是在加沙那样的瓦砾中，孩子一直长不大。

当然从纯粹现实主义的角度理解，以色列反而是中国国家利益真正的同路人。只要以色列存在，中国和一个庞大的伊斯兰世界就没有“文明的冲突”。

想想一个小小的埃苏丹，在万里之外就曾经造成过多少麻烦。中美俄欧，谁愿意卧榻之侧出现一个真正的萨拉丁？

这才是鼻屎大的以色列干出这么多断子绝孙的事情却迟迟得不到清算的根本原因。至于什么狗屁铁穹系统，在真正的万炮齐发面前顶个屁用。

## 2: 20250618-003440

在雅加达机场上，看到全球超市之王circle k，本地超市Indomaket。看见了中国的安克电池，路上还看到了海螺水泥。中国足迹，越来越多。

澳大利亚的Circle k它正在试图吞并日本便利店7-11，看起来没有进展。一瓶依云矿泉水14人民币，普通的水是6块钱，一个汉堡包11元人民币。

印尼盾换成人民币，我第一天到印尼按照抹掉4个0再乘以五。很轻松的换算，洋洋得意。

“抹四乘五”，这是我从越南盾换成人民币学来的一招，从越南一个企业家而来。

还是民间有高手。

朋友留言说，可以抹掉三个0，再除以2。“抹三除二”这个显然是更接近于本地人的智慧。第一印尼的价格，往往是隐含以“千”为单位，16000直接就写成16。因此只需要把看到的数字直接除以2就可以。第二是人民币兑换比例。印尼盾跟人民币的比值差不多2200：1（近似2000），而越南盾是3500:1。

前者显然更适合于除法，后者则适合乘法。

一个国家一个令在，此处好规则在彼处未必好用。“抹四乘五”与“抹三除二”代表了不同国家的特殊性。

这不就是中国企业在海外的组织所需要的灵活性吗？

中国的企业目前在海外，往往是强总部架构。总部指标属于指令分解往下灌，完全不考虑地区的差异性。

这种陈旧而笨重的管理，很难适应海外的惊涛骇浪。

目前印尼政府开始进行了严格的税务和关务审计。以前往往都是5年一次，而现在提前到一年一次。这就是提前收钱，财政亏空就会产生这种方式吧。这就是爪哇智慧。

这种随时破规不可预测的事情，在总部是难以理解的。

外派管理者这个时候就呈现出“孤勇者”的无助。无奈写满脸，焦虑中苦苦寻找对策。总部是不管不顾只催租子，而跟当地政府的对话渠道暗黑不通。

而久耕当日韩企业则一定有办法，突破对话通道这一点。日资企业的商会和振兴贸易机构，它会有多个触角，为群体发声。中国则是单打独斗。

如果强势总部一意孤行，就可能给地方公司造成巨大的伤害。

很多时候稍微观察海外公司与总部的关系就能发现，总部的行政部门其实是出海的绊脚石。他们对海外公司，本身是一种阻碍，而不是促进。

当下地缘政治风险陡峭，如果从来没出过海的管理者，怎么可能对海外做出判断和下出指令呢？

在海外的公司一定跟总部不一样。龙生九子，各有不同，总部需要敬畏和放手子公司的灵活性。

生存需要小技巧，出海需要大智慧。万千线索，风浪飘摇，唯充分授权不变，唯随机应变不变。`大出海`

## 3: 20250618-005926

雅加达的清晨五点。难得路上清荡无车。 酒店对面的穆斯林教堂，每天早晨4:30就有人祈祷，声浪不绝于耳。这次来雅加达，拜见了不同的客户，听见了不同的声音。有的队是官员的腐败，有的是政策黑盒的无奈。

然而有2点是肯定的。一个是，这里存在着巨大的机会。

第2个就是最大的不确定性，其实是来自中国企业的蜂拥效应。后者的群体性陡增和不按常理出牌正在恶化这里的环境，最后可能会造成一种生态性的雪山崩塌。

一家中资品牌车企是这里的一个传奇，快速获得市场份额。而各行各业的人都在思考，如此不顾成本横扫意欲何为？如此异乎寻常的非常规行为，背后一定有魔鬼细节的交换。来这里的中国投资实在太多了，方方面面，连和府捞面也在加入。

除了应对本地规则，企业头疼的还有培养的本地人员被双倍挖走。印尼最缺技能员工，中企的印尼骨干最抢手。可能现在最容易发财的行业，应该是“新东方蓝翔技技校”。懂中文懂技术，最受欢迎，和争抢。

来的企业多并不可怕，就怕就是“无知无畏、无序无规”。

起步就是过度竞争，会引发的行业规则践踏。

中企快速做大，会形成对本地的替代碾压。这些都会缓慢地沉淀成一种底层的敌意。

这些四下流动的情绪发酵，在未来是否会触发某一个大坝破堤的开关？欣欣向荣的繁荣引发的敌意综合症，才是中企最大的风险。印尼有一种魔鬼规则叫做“爪哇智慧”，请君入堂，关门算账。早晨五点半，四处隐黑，出城往机场的高速已经堵车了。这是雅加达最擅长的`大出海`

## 4: 20250618-015904

Language Models in Plato's Cave

Why language models succeeded where video models failed, and what that teaches us about AI

Sergey Levine

Jun 09, 2025

From its original inception, the study of artificial intelligence has been intertwined with the quest to understand human intelligence. Predicated on the notion that the mind is fundamentally computational – that is, it can be modeled as an algorithmic framework independently of its underlying computational substrate or “hardware,” – AI researchers have sought to draw inspiration from what we understand about the mind and the brain to construct artificial minds that reflect the flexibility and adaptability of human intelligence. Some researchers have even speculated that the complexity and flexibility of the mind is derived from a single algorithm applied throughout the brain to acquire all of its diverse capabilities. This hypothesis is particularly appealing for AI researchers, as it suggests that our job might actually be quite simple. Instead of painstakingly designing all of the functions that we would want an artificial mind to perform, we might only need to discover this single ultimate algorithm, and then let it loose on the real world to acquire all the capabilities of the human mind through direct experience.

Large language models (LLMs) have been very successful at emulating certain aspects of human intelligence, and while there is no question that there are still gaps in their capabilities – gaps that are big enough to fit even the most fundamental criticisms – the LLM approach to AI has repeatedly overcome major challenges and objections, acquiring new cognitive capabilities with each order of magnitude increase in model and dataset size. The algorithms underlying LLMs, based on next token prediction and RL-based fine-tuning, are also remarkably simple. This might lead us to suppose that these algorithms might actually resemble the hypothetical single ultimate algorithm that the brain uses to acquire all of its diverse capabilities. If true, this would be exceptionally appealing. Not only can human intelligence solve a huge range of problems, but it can also discover new solutions to entirely new problems. Humans have come to dominate the world around them not because of our ability to recall facts or solve math problems, but because of our ability to quickly learn from experience and adapt to novel situations. Capturing this capability in an AI system would be a tremendous leap forward.

There is however a crack in the foundation of this argument. Even before the earliest Transformer-based language models, AI researchers were busy studying a seemingly very similar problem: analogously to next-token prediction in LLMs, researchers had tried for about a decade to extract meaningful representations and physical understanding by training models for next-frame prediction on videos. On the surface this problem seems very similar: just like an LLM derives a deep understanding of the world by predicting the next token in textual data from the web, a video model might derive a deep understanding of the world by predicting the next frame in video data. In many ways this is even more appealing and seemingly more powerful: video data contains a lot more information (cf. Yann LeCun’s cake), it can be obtained in huge quantities not just from the web, but simply by pointing a camera at a busy street, and it can capture not just the words that people use to communicate with each other, but also the richness and complexity of the physical universe. A robot that flies away to explore a distant planet, like a person stranded on a desert island, wouldn’t benefit much from learning via next-token prediction on text, since there would be no one to provide it with text there, but it can still obtain plentiful video data. Unfortunately, things didn’t pan out the way that video prediction researchers had expected. Although we now have models that can generate remarkably realistic video based on user requests, if we want models that solve complex problems, perform intricate reasoning, and make subtle inferences, language models are still the main and only option. We can’t ask Veo 3 to estimate whether the island of Hawaii contains more cubic meters of rock than Mt. Everest, but ChatGPT can complete that task with gusto. This might seem like a mystery, since LLMs “see” much less of the physical world, and are seemingly exposed to a much thinner slice of reality, and yet acquire much more sophisticated cognitive abilities even when it comes to spatial and physical inferences.

In science, we might suppose that the more simple, elegant, and powerful a theory is, the more likely it is to be the right one – there are many ways to write down an equation to describe the oscillation of a spring, but we take Hooke’s law to be the “right” theory because it provides both remarkable simplicity and high predictive power. Similarly, we might suppose that if we have an algorithm that is simple, elegant, and explains similar essential functions as the human mind, then it is likely to be the right model of the mind’s computational processes. That is, if LLMs are trained with a simple algorithm and acquire functionality that resembles that of the mind, then their underlying algorithm should also resemble the algorithm by which the mind acquires its functionality. However, there is one very different alternative explanation: instead of acquiring its capabilities by observing the world in the same way as humans, LLMs might acquire their capabilities by observing the human mind and copying its function. Instead of implementing a learning process that can learn how the world works, they implement an incredibly indirect process for scanning human brains to construct a crude copy of human cognitive processes.

Of course, there are no people strapped to fMRI machines in data centers that train LLMs (that I know of). Instead of directly scanning real live brains, LLMs reconstruct the human mind through the shadow that it casts on the Internet. Most of the text data on the web is there because a person pressed buttons on a keyboard to type out that text, and those button presses were the result of mental processes that arose from underlying cognitive abilities: solving a math problem, making a joke, writing a news story. By acquiring compressed representations of this text, the LLM is essentially trying to reverse engineer the mental process that gave rise to it, and indirectly copying the corresponding cognitive ability. While the Human Connectome Project is busy reconstructing the human brain neuron by neuron, LLMs are trying to skip the neurons all together and reconstruct the mind from the shadow it casts on the Internet.

This explains why video prediction models that learn about the physical world have so far not yielded the same results as next-token prediction on language: while we might hope that models that learn from videos might acquire representations of the physical world in the same way that humans learn through experience, the LLMs have managed to skip this step and simply copy some aspects of human mental representations without having to figure out the learning algorithm that allowed humans to acquire those representations in the first place.

This is both exciting and disappointing. The good news is that we’ve been able to build the world’s most powerful brain scanner without even intending, and it actually works, simulating at least some fraction of human cognitive ability in an AI system that can answer questions, solve problems, and even write poems. The bad news is that these AI systems live in Plato’s Cave. The cave is the Internet, and the light shines from human intelligence, casting shadows of real-world interactions on the cave wall for the LLM to observe. In Plato’s allegory, leaving the cave and observing the world in daylight is necessary to understand the world as it really is. The shadows on the wall are only a small, distorted piece of reality, and crucially the observer in the cave doesn’t get to choose which shadows are presented to them. AI systems will not acquire the flexibility and adaptability of human intelligence until they can actually learn like humans do, shining brightly with their own light rather than observing a shadow from ours.

In practice, this means that we would expect LLM-like AI systems to be proficient in reproducing human-like cognitive skills, but relatively poor at actually acquiring new skills, representations, and abilities from experience in the real world – something that humans excel at. It also implies that implementing this kind of flexibility would require us to figure out something new: a way to autonomously acquire representations from physical experience, so that AI systems do not need to rely on brain scans mediated by text from the web.

However, as AI researchers and engineers, we should also be pragmatists: these brain scan LLMs are really good, and if we want to reproduce a human-like mind in a machine, starting with a good working prototype seems like a great idea. The challenge AI research faces over the coming decade is how to extract the right lesson from the success of LLMs, but also discover the principles that underlie real flexible and adaptive intelligence – the kind that can learn from experience, understand the physical world, and discover entirely novel solutions to new problems that no human being had solved before.

柏拉图洞穴中的语言模型

为何语言模型成功而视频模型失败？这对人工智能的启示

作者：谢尔盖·莱文

2025年6月9日

人工智能研究自诞生之初，便与理解人类智能的探索紧密交织。基于“心智本质上是可计算的”这一核心理念——即心智可被建模为一种独立于底层计算载体（或称“硬件”）的算法框架——人工智能研究者试图从我们对心智和大脑的理解中汲取灵感，构建能体现人类智能灵活性与适应性的人工心智。一些研究者甚至推测，心智的复杂性和灵活性源于一种单一算法，该算法通过大脑整体运作获得所有多样化能力。这一假设对人工智能研究者极具吸引力，因为它暗示我们的工作可能异常简单：无需费力设计人工心智所需的所有功能，只需发现这一终极算法，然后将其释放到现实世界中，通过直接经验获取人类心智的全部能力。

大型语言模型（LLMs）在模拟人类智能的某些方面已取得显著成功。尽管其能力仍存在明显缺陷（甚至足以容纳最根本的批评），但LLM方法已反复克服重大挑战与质疑，并随着模型规模和数据量的指数级增长，持续获得新的认知能力。LLM的核心算法（基于“下一词预测”和强化学习微调）也异常简洁。这或许让我们推测：这些算法可能近似于大脑用于获取多样化能力的假设性终极算法。若此猜想成立，其意义将非同寻常——人类智能不仅能解决海量问题，还能为全新问题发现解决方案。人类之所以主宰世界，并非因记忆事实或解数学题的能力，而是因快速从经验中学习并适应新情境的能力。若能在AI系统中复现这一能力，将是巨大的飞跃。

然而，这一论证的根基存在裂痕。早在最早的Transformer语言模型出现前，AI研究者已研究一个看似极其相似的问题：类比于LLM的“下一词预测”，研究者曾花费约十年时间，通过训练视频的“下一帧预测”模型来提取有意义的世界表征和物理理解。表面看两者高度相似：正如LLM通过预测网络文本中的下一词来理解世界，视频模型或可通过预测视频中的下一帧达成类似目标。从许多角度看，后者甚至更具吸引力且看似更强大：视频数据包含更丰富的信息（参考Yann LeCun的“蛋糕比喻”），其获取规模不仅限于网络，仅需将摄像头对准繁忙街道即可；它不仅能捕捉人际交流的语言，还能记录物理世界的复杂性与丰富性。例如，探索遥远星球的机器人或荒岛求生者无法从文本的“下一词预测”中获益（因无人提供文本），却仍能获取海量视频数据。遗憾的是，视频预测研究未达预期。尽管现有模型能根据用户需求生成逼真视频，但若需解决复杂问题、执行精密推理或进行微妙推断，语言模型仍是唯一选择。我们无法要求Veo 3估算夏威夷岛的岩石体积是否超过珠穆朗玛峰，但ChatGPT可轻松完成此任务。这似乎是个谜：LLM对物理世界的“观察”远少于视频模型，接触的现实片段更单薄，却在空间与物理推理等任务中展现出更复杂的认知能力。

科学领域常假设，理论越简洁、优雅且强大，越可能是正确的——描述弹簧振动的方程可能有多种形式，但我们视胡克定律为“正确”理论，因其兼具简洁性与高预测力。同理，若某算法简洁、优雅且能解释与人类心智相似的核心功能，它便可能是心智计算过程的正确模型。即，若LLM通过简单算法训练获得类心智功能，其底层算法应近似于心智获取功能的算法。然而，存在另一种截然不同的解释：LLM的能力获取可能并非通过人类式观察世界，而是通过观察人类心智并复制其功能。它们未实现“学习世界运作规律”的过程，而是通过间接扫描人脑构建人类认知过程的粗糙副本。

当然，训练LLM的数据中心并未将真人绑在fMRI机器上（据我所知）。LLM并非直接扫描活体大脑，而是通过互联网上人类心智的“投影”重建心智。网络文本数据的存在，源于人类通过键盘输入文字，而这些按键行为源自底层认知能力驱动的心理过程：解数学题、讲笑话、写新闻。通过压缩这些文本的表征，LLM本质上是在逆向工程生成文本的心理过程，间接复制相应认知能力。当“人类连接组计划”忙于逐神经元重建大脑时，LLM正试图跳过神经元，直接从互联网上的心智投影中重建心智。

这解释了为何学习物理世界的视频预测模型尚未取得与语言“下一词预测”相当的成果：尽管我们希望视频模型能像人类通过经验学习一样获取物理世界表征，但LLM已跳过这一步，直接复制人类心智表征的某些方面，而无需破解人类最初获取这些表征的学习算法。

这既令人兴奋又令人失望。好消息是，我们无意中构建了全球最强大的“脑扫描仪”，且它确实有效——在能回答问题、解决难题甚至写诗的AI系统中，至少部分模拟了人类认知能力。坏消息是，这些AI系统生活在“柏拉图的洞穴”中。洞穴即互联网，“光源”来自人类智能，将真实世界互动的投影投在洞穴墙壁上供LLM观察。在柏拉图的寓言中，走出洞穴、在日光下观察世界是理解真实世界的必要条件。墙上的投影仅是现实的微小扭曲片段，且关键的是，洞穴中的观察者无法选择呈现何种投影。AI系统唯有像人类一样学习（发出自己的光而非观察我们的投影），才能获得人类智能的灵活性与适应性。

实践中，这意味着类LLM的AI系统擅长复现类人认知技能，但在从现实经验中获取新技能、表征和能力方面表现欠佳——而这正是人类的强项。这也暗示，实现此类灵活性需探索新方法：让AI系统从物理经验中自主获取表征，而非依赖互联网文本中介的“脑扫描”。

然而，作为AI研究者与工程师，我们亦需务实：这些“脑扫描式”LLM已非常强大，若想在机器中复现类人心智，从一个优秀原型出发是明智之举。未来十年，AI研究的挑战在于：既从LLM的成功中汲取正确经验，又发掘真正灵活适应型智能的底层原则——那种能从经验中学习、理解物理世界，并为人类未曾解决的新问题发现全新解决方案的智能。

## 5: 20250618-033301

刘强东今天传出来的那份内部讲话还是很有水平的，虽然都是内销转出口的意图，至少比那种念稿表演的所谓内部讲话要有人味得多。

他说京东最近5年京东没有任何新业务产生，在时间轴上依然是以他出屌事之后被迫淡出管理为起点，用来传递「公司没我还是不行」的信号，考虑到他回归以来的这些动作，客观上把逐渐掉队的京东重新带到了舞台中央，没毛病。

互联网公司的老板们真的应该多看看刘强东的表达方式，轻飘飘的一句「从供应链而非卖饭菜身上赚钱」，直接破局了从外卖到买菜业务困扰行业多年的指责基础：怎么别人家的科技公司都在发射火箭探索星辰大海，你们却在惦记着从老百姓碗里的几捆白菜呢？

刘强东对品牌商的支持也很高明，电商行业这几年都不怎么敢走品牌叙事，因为经济压力大，消费者不买账，相信牌子=割韭菜的公式，于是都在讲工厂、讲白牌、讲产业带，刘强东现在出来力挺品牌，用的也不是爹味式的原理教育，而是先是自贬一通，说京东国美苏宁这种零售商创造的社会价值远远比不上品牌商，所以要把效率省下来的利润让给品牌商，品牌活下去了，经济才有质量，工人才能涨工资。

这些话没有任何新意，不存在哪一个字是刘强东自创的，但是放在新闻里就是八股文，放在市场上就是假大空，但被刘强东这么串起来，逻辑顿时就盘通顺了，用户持有的消费立场也转向了产业立场，跟能不能买到便宜货比起来，赚更多钱好像更加重要。

这就是设置议程的能力。

我写这些，肯定又会引起两种相互矛盾的反应，一边是有人觉得这是京东买的商单，另一边则是京东的PR认为我在讽刺刘强东过于机巧，其实都不碍事，甚至可以说，机巧在我这里未必是一个贬义的概念，再不济总比愚笨好。

比如刘强东说到去年公司收入1.1万亿，利润只有400亿，这很明显的就是在给短视频博主们下套，大家拿去对比阿里腾讯美团就会发现，卧槽京东简直太良心了，其他几家都不是东西啊，这固然和不同业务结构的区别有关——京东的自营模式本来就容易推高营收——但下沉市场根本看不懂也没兴趣搞懂这些好吗，给东哥上灯牌就完事儿了⋯⋯此为鸡贼的一面。

然后刘强东又说京东十几年里给员工交了1000多亿的五险一金，「这些钱原本都能合法的成为我刘强东的财富，在中国外包是合法的，但京东从来没做」，这又是京东完全没得黑的地方，一边说企业必须赚钱，因为失败的企业会给社会带来巨大的负担，一边说不把利润当成第一大追求，欢迎同行都能通过舍弃1000亿的方式来装一装⋯⋯此为实诚的一面。

鸡贼加上实诚，不就是机巧么？

再就是加班不可避免、只好用涨薪抚慰员工，以及跨境电商没戏、必须搭建本地采销网络的观点，都是很能自圆其说的观点表达，不说绝对正确与否，在说服性上可打满分，也能理解京东员工近年以来的兴奋感，指挥官上前线的鼓舞作用太大了。

最近张朝阳还说如果让他在今天白手起家创业的话会选择做自媒体，道理是那么个道理，但我的评价是，也就是山中无老虎猴子撑大王了，像是刘强东这样真正从江湖里爬出来的人精，随便在什么场合比划几句，流量都能秒杀那些戴着痛苦面具强迫自己营业的企业家网红。

这才叫老天爷赏饭吃。

## 6: 20250618-062021

`AI教父称水管工的工作要比白领安全`【诺奖得主辛顿：AI替代的是“普通智力”，水管工的工作比白领安全】被誉为“人工智能教父”的杰弗里·辛顿（Geoffrey Hinton）日前在接受一档播客“The Diary Of A CEO”采访中尖锐地指出，过往工业时代技术革命（如ATM机）无法与AI革命相提并论，因为前者替代的是体力劳动，而AI替代的是认知劳动。当一个社会中“普通的智力”不再具有价值时，绝大多数依赖脑力劳动的工作岗位都将被颠覆。

辛顿常被称为“人工智能教父”，他以其类神经网络方面贡献闻名。2024年，他因深度学习领域贡献获诺贝尔物理学奖，目前是多伦多大学计算机科学系教授。

在最新的深度访谈中，辛顿系统性地阐述了他对AI发展的深切忧虑。他指出，“重复性、枯燥的脑力劳动”将首先被AI取代，这类工作通常涉及办公室类任务。他以自己的侄女工作为例，称他侄女在处理一封投诉信时，因为AI的辅助，从25分钟骤降到5分钟，这意味着一个人可以完成过去五个人的工作。未来“一个人+AI助手”的组合将能完成原本需要10人完成的工作。他举例说，律师助理、在呼叫中心工作等岗位最危险，如果他现在还在呼叫中心工作，会“非常害怕”。

辛顿认为，“现在一个不错的选择是去做水管工。”类似水管工这类蓝领工作被AI取代的风险较小，像法律助理、律师助理这样的人，他们很快就不再被需要了。

而这也会进一步扩大贫富差距，辛顿称，在公平分配事物的社会中，如果生产力大幅提升，每个人都应该过得更好。但如果能用人工智能取代很多人，那么被取代的人将会过的更糟。提供人工智能以及使用人工智能的公司则会过得更好，所以这将扩大贫富差距。

对于“AI能创造新就业”的观点，辛顿表示怀疑。他认为一旦AI足以完成大多数脑力工作，人类能做的事情将所剩无几，“你必须具备极高技能才能从事人工智能无法胜任的工作。”

事实上，人工智能有可能会减少招聘，特别是入门级职位。他援引风险投资公司SignalFire今年5月发布的一份报告称，大型科技公司（如Meta和Google）招聘应届生的比例在一年内下降了25%，这与AI技术替代低层岗位密切相关。

受人工智能影响的不仅仅是科技行业，华尔街也出现了受影响的迹象。摩根士丹利3月宣布裁员2000人，彭博社1月份发布的一份报告显示，未来五年内，全球93家大型银行（包括花旗、摩根大通）预计因AI自动化裁员多达20万人。via澎湃新闻

## 7: 20250618-064757

黄子韬这次被卷进卫生巾事件，说实话挺冤的。他一个男明星敢做女性用品，本来就需要勇气，至少说明他真的想为女性健康做点实事，而不是光嘴上说说。

这次所谓的“黑色异物”事件，目前就一两个人在网上发帖，连具体是不是产品问题都没实锤，结果一堆人就开始跟风骂，这对他和品牌都不公平。

黄子韬的性格大家都知道，直来直去，有问题他肯定会认，但这次连调查结果都没出来就被扣帽子，未免太着急了。而且他之前公开怼过行业乱象，现在自己做的品牌被质疑，换别人可能早就甩锅了但他团队第一时间就回应了，态度至少是端正的。

有多少是真的关心产品质量，还是纯粹想看他翻车？明星做实业不容易，该监督的监督，但也得给人改进的机会，一棍子打死没意思。黄子韬要是真想圈钱，大可以接代言割韭菜，何必自己搞品牌还惹一身腥？等等官方结果，别急着下定论。

`黄子韬回应卫生巾问题` http://t.cn/A6erunxC

## 8: 20250618-071023

大家一定要搞清楚，男女对立在我们国家过去一直是缓和社会矛盾的利器，现在遇到问题是因为缺少了增量。这里面最典型的是房地产。我们国家过去执行的是福利分房制度。在福利分房年代，是不存在男女婚姻对立的。原因很简单，男女是要结婚之后，才可以向单位申请福利分房。一对夫妻一结婚，就要为了彼此的个人利益紧密协作，去向政府要福利。

男方单位福利好，就找男方要；女方单位房子好，就找女方单位要。换到农村也是一样，是夫妻结合，向村集体要土地。

所以在50-70初这一代人，是几乎没有男女对立问题的。婚姻是一种天然的协作，他们以男女为单位，一起向社会去争取福利。

接下去就是改制。福利分房制度是在2003年彻底终结，接着是所谓的商品房制度。也就是说，房子不是分配，而是要掏钱买了。

社会福利没有了，那么就是赤裸裸的资本竞争。你拿钱去买房，没钱就没房子。房子就成了大家看得见摸得着的阶层。

这个时候宣传就成了男性有义务去购买婚房，而提供给女性的，是法律意义上的空头支票。最典型的就是房产加名，设立的就是“加名即赠予”。包括彩礼制度也是一样的。

男性，是有“义务”要买婚房的；给女性的，是房产加名。女性找到合适的对象，结婚后做房产加名，就可以获得资产，而这对男性来说就意味着他的资产要转移给女方。

你发现没有，这种制度下，男女怎么可能不对立？

那么为什么当时没出问题呢？

因为有增量，也就是房价在迅速的增长。我国的房地产市场，整体从03年一直涨到了2018年，换到一线城市，这个涨幅高点甚至延续到了2021年。

对于男女来讲，他们虽然利益对立，但是只要一起协作，比如六个钱包一起买房，在这个时间点里面，还是赚钱的。

有增量的时候，搞男女对立，也能很和谐。夫妻一起，早买就是早赚。

那么现在为什么不行了？

房地产市场很明显在下行。没有增量了。这个时候你去看市场上的成交量，就是大幅度的在下降。以前说的结婚刚需，突然间就没了。原因很简单，放在2015年，一个女孩子遇到男方手里有30万，合理选择是拿出积蓄和男方一起买婚房，因为买房涨；在今天，也就是2025年，这女孩子的合理选择就是把这30万当作彩礼要到自己手里，落袋为安。

社会整个经济环境变了，人的行为就是会变的。没有增量了，之前解决社会问题的利器男女对立，也就成问题了。`热点解读`

## 9: 20250618-074920

杭州万象城绑架的事情不知道大家有看到没有。

全网都没声了，南方系控制媒体的能力确实比北方强，如果东北出现这种事，最起码要被骂上头条三周。

女生开车被劫持，想办法给男朋友求救，男朋友立刻报警，警察居然直接给女生打电话，而且打了两次，没人接，就散了，觉得是报假警。

男朋友想办法通过ipad，查到了女生的定位，联系了当地警方，结果当地警方没带枪，就上去拦车盘问。

在警察的围观注视下，劫匪连捅了人质20多刀，然后自杀。

全程警察束手无策，只能围观。

网友在网上热议这件事，有不少小畜生给警方洗地，

说你根本不知道国内报假警的人有多少，治安这么好，突然有个男的，拿女朋友聊天记录来报警，换你是警察你也不信，你只会觉得小情侣吵架，闹着玩，根本不会当真。

100件事里，起码99件是这样。

实在怪不得警察。

这个不能说明怪不了警察，

这个只能说明国内缺乏两个重要机制：

1，对报假警的惩罚机制，只要报假警，立刻抓起来，罚款拘留，情节严重者刑事处罚。

无理取闹的人自然就不敢乱报警闹着玩。

2，对警察的投诉和监督机制。

这件事的后果这么恶劣，当地警方有受到追责吗？

打110，结果给人质手机直接打电话，还是打两次，这样的大聪明是谁，为什么名字没有被爆出来，为什么没有被追责？

全程围观呆若木鸡的民警叫什么，是否涉及渎职，是否要被开除公职？

杭州警察的工资是非常高的，都有几十个W，

这么高的工资，职业素养却成这个样子，

这个是杭州所宣传的，环境包容，廉洁高效么？

## 10: 20250618-080615

根据西方媒体和以色列披露的信息，这次以色列袭击伊朗里最讽刺的事情在于：以色列启动了在伊朗的200名潜伏人员充当定位或者情报活动，而这200人里有很多是在伊朗生活的印度公民。

最近伊朗抓捕了73名可疑人员，其中又有不少印度公民（去年伊朗把一个港口交给了印度运营，因此入境 了大量的印度员工）。

而前不久的印巴冲突，伊朗竟然还是支持印度的，并且和印度签署了《全天候战略合作伙伴协议》。

但这次以色列袭击伊朗后，伊朗在上合组织里寻求声援，所有国家都谴责了以色列的袭击，唯一声明不参与谴责的那个国家，就是印度。

## 11: 20250618-084238

【国家统计局发布5月份分年龄组失业率数据 】财联社6月18日电，国家统计局发布5月份分年龄组失业率数据。5月份，全国城镇不包含在校生的16-24岁劳动力失业率为14.9%，不包含在校生的25-29岁劳动力失业率为7.0%，不包含在校生的30-59岁劳动力失业率为3.0%。 ​​​

## 12: 20250618-130441

接着聊聊伊朗。我两次出差都在节点:一次是在达成伊核全面协议后的2016年初，当时全世界领导人都排队去德黑兰，期待大单签署，我国排第一，伊朗总统说不会忘了患难中帮衬的友国。第二次去就是特朗普撕毁协议后的2019年，经济又陷入困境。但这个被制裁46年的国家，一直没有崩溃。我很好奇。便找各种渠道了解，供大家参考。

2023年世界银行的统计是GDP增长5%.人均四千多美金。伊朗没有加入 WTO 虽然有美国制裁和国际制裁，但是1979年以来，伊朗已经与69个国家签署了138项贸易和关税协议，与52个国家签订了双边贸易协议，与42个国家签订了避免双重征税。中国连续12年是伊朗第一大贸易伙伴。另外，伊朗凭借地理优势对波斯湾沿岸国家、高加索地区国家、中亚独联体国家等市场都有较好的辐射，所以伊拉克、阿联酋、土耳其、阿富汗、巴基斯坦是伊朗的第二、三、四、五、六大贸易伙伴。伊朗前五大进口来源国为中国、阿联酋、土耳其、德国和俄罗斯。前五大出口目的地国为中国、伊拉克、土耳其、阿联酋和阿富汗。出口产品五成为石化和石油产品，二成是矿产品，二成是农产品和食品，一成为工业产品、凝析油和手工业品。伊朗吸引外国直接投资存量主要集中在原油、天然气、汽车、矿产、石化、食品药品行业。欧洲和亚洲是外资来源地。

另外，伊朗的内循环能力比较强，现在对石油出口的依赖程度也降到了50%以下，由于近些年一直发展非石化经济，伊朗的经济仍可支撑，工业品能基本满足国内需求，由于伊朗人的教育水平高，人员素质高，工业品开发速度快，农产品也能自给自足，所以经济社会发展可以内循环四十六年而不崩溃。而且友好国家的有效帮助，在被孤立时，也能保证基本盘。

还有很关键的一点就是，伊朗的隐型经济很发达。民选政府控制的国有企业占比重很小，政府预算根据石油价格来定，在100亿美元到600亿美元之间。而宗教部门掌控的基金会掌握着大量财富，发挥着蓄水池和救济贫民的功能，这些基金会自成一体，有产业有雇员有内部分配。比如穆斯塔法基金会和穷人基金会，资产都在百亿至千亿美元，在政府之外发挥着作用，这也是政教合一的伊朗的一大特点。这些基金会都是当年霍梅尼宗教集团骨干通过剥夺国王和外逃富人资产成立的，他们办企业，也在掌握各地清真寺的讲课收入，必要时也救济穷人。所以他们的收入是企业收入加入清真寺收入。另外一个重要的经济来源是革命卫队，伊朗伊斯兰革命卫队不仅管控导弹军、海军、边防部队，以及一部分空军，还掌握优质企业、矿山、油田作为经费来源，而且与宗教基金会也有联系。所以政府经济收入+宗教基金会收入+革命卫队经济收入构成了伊朗的经济总收入格局。伊朗特殊的政治经济宗教混合体制使其经济保持了韧性和弹性。除此之外，大约有200万伊朗裔在美国，比较优秀也积累了大量财富，动员起来也不可小觑。

试想如果面临同样的金融、经济、能源贸易、武器禁运、航运等制裁，那些境况相似的国家如何应对？

由于公开资料极为有限，我只能从伊朗四十六年来应对制裁的历史来分析，认为伊朗形成了一整套对抗制裁的法律、政治、宗教体系和政策工具箱，涵盖了国家治理的各个方面，这一整套体系通过多年积累，已经常态化，完全可以支撑内循环。

总结十点可供借鉴：

1.  避免制裁措施集中实施，避免叠加效应导致经济崩溃，采取了拖延、谈判、有进有退战术，以时间换取了空间。

2.  体现了非国有经济的重要性，市场主体多样化，民营企业大有作为。

3.  高效进行产业结构调整，出口产品多样化，出口地多元化。尤其在非制裁领域，着重双边协议，双边更灵活，更容易谈合作。

4.  证明SWIFT不是唯一的渠道，伊朗已经打通外汇收入其他渠道但信息保密。

5.  凸显数字货币和数字科技的重要性。

6.  显示出教育优势，伊朗国民教育程度高，自主研发和技术创新周期短，能较好解决卡脖子问题。

7.  具有灵活的外交手段，得到大量国家外援。

8.  拥有相当规模的有实力的海外侨胞群体。

9.  国内管控力量的动员能力强，治安可控。

10.  相比其他中东国家，伊朗基本没有恐怖主义破坏活动发生，具有较高的宗教问题处理能力，发展环境稳定。

## 13: 20250618-175304

以色列不堪一击，中东有无数次机会推平以色列。

上次哈马斯组织的阿克萨洪水已经很明显了，这么大规模的行动摩萨德一无所知。

居然有人说以色列是故意的，你这个玩笑开的有点大，摩萨德那么多人，内塔利亚胡那么多政敌，他有这个本事封锁消息？他要敢故意的，早就去吃牢饭去了。

1973年10月6号第四次中东战争爆发，埃及和叙利亚一路平推，尤其埃及派工兵连夜搭浮桥，带坦克冲过苏伊士运河；

用高压水枪冲垮以色列的沙墙防线，埃及士兵顶着以军炮火猛冲，两天就抢回了西奈半岛一大片地盘！以色列军队夺路狂奔.....

同一时间，叙利亚猛攻戈兰高地，

以色列顾头不顾腚,被打得手都还不了，开局即血崩,王牌坦克部队被埃及反坦克导弹当靶子打爆。

只要埃及叙利亚再坚持7天，以色列必定崩溃。

眼看以色列要完，美国立马跳出来劝架，说别打了！联合国开个会，停火谈判吧！结果埃及和叙利亚就真的暂停了，美国空军3天狂飞567趟，给以色列送坦克导弹战斗机；

中情局把卫星拍到的埃及布防图发给以色列，相当于考试直接给答案；

国务卿基辛格哄骗苏联：放心！我会按住以色列的！

萨达特以为美国真来主持公道，立马命令军队停火，原地待命。

结果72个小时的时间，以色列找到埃及防线漏洞，派装甲部队偷偷渡过苏伊士运河，然后突然撕毁停战协议发动总攻，包了埃及第三军团的饺子！

此时埃及才惊觉上当：

前线士兵在停火期间蹲战壕里吃瓜，结果被以军包圆；

西奈半岛还没捂热的土地又被抢回去；

美国这时候又出来威胁：再敢动，我亲自下场揍你！

最后埃及和叙利亚大败，稳赢的局面生生被搞输了。

伊朗只需要连续轰炸以色列15天，局势就会变。

有人说伊朗没那么多导弹，美军原来透露的伊朗有15000枚导弹，我们就打个折，就算伊朗有4000颗，现在才打了320颗，你说够不够？

但是局面这么明显，我都说最终的胜负我不知道，因为历史无数次的证明了：

给你机会你踏玛的不中用啊！

我一看到沛泽希奇扬哪里能有信心，现在谁知道有多少人等着带路.......

`微博新知`

## 14: 20250618-202814

朝鲜90年代基本是天崩，苏联直接没了，92年中韩建交，

他不过一个2000多万人的国家能怎么办？

一个国家多数还是靠自己。阿富汗政府军当年有美军，

南越当年有美军帮忙，伊拉克政府军和ISIS作战的时候也有美军帮忙，

都打了个啥？

2000年以后伊朗没有今天这么被动，别忘记了，当年伊朗搞的有模有样的，

美军帮伊朗清理了萨达姆，去了心头大患。

实际上一直到叙利亚没崩之前，伊朗情况没有今天这么糟。

也是因为没有这么糟，才有什么七哥一天到晚的下大棋。

如果今天伊朗的那些指挥官是被以色列空军炸死的，那我无话好说，

科技不如人，以色列有美国帮忙，吃亏就吃亏了，

但是相当多指挥官是被以色列特工炸死的。这又和地缘有什么关系？

很多人以为朝鲜战争打完了就完了，

实际上自朝鲜打完了，朝韩双方互相渗透攻击200多次。

大量的朝韩特工互相渗透。

68年朝鲜124部队突袭青瓦台，韩国死26军警，4命美军被杀。

当年朝鲜巡逻艇俘虏美国海军普韦布洛号，俘虏其船员。

蔚珍-三陟登陆，韩国7人被俘，40名正规军死亡，美军死3名伤3名。

69年朝鲜米格击落美国预警机，美军死31名。

什么延坪岛炮击之类的我都不算了。

朝韩都是互相渗透的，就跟以色列渗透伊朗一样，

大国的保护伞不是时时刻刻都有用。

总有人觉得只要往大国这边一靠就万事无忧，

如果是这样，阿富汗政府军，南越军队是如何一败再败的？

## 15: 20250618-212127

你的高中老师在报考志愿这事上帮不了你，你的家长也同样帮不了你。你的高中老师跟商业社会脱节很久，他们长期生活在一个独立封闭的小社会里，有一套完全封闭的理念和评价体系，我不是说这样不好，从培养做题家和让你提分来说，他们可能非常牛。

但是，他们并不具备指导你人生的能力，除非你的未来职业规划是成为一名中学教师，否则在报志愿的选择上，你无从向他请教。

还有一点不方便说的原因，就是高中教师的KPI大多只跟一本率，重本率，本科率有关，至于你学的农业还是计算机，开的是挖掘机还是航天飞机，只要是同级别的学校，对他而言是一样的。所以，甚至有不少老师，为了追求升学率，会鼓励你报所谓冷门专业。

至于大多数家长，根本不了解大学的专业设置，不少人只是听说生物很火，就让孩子报生物，计算机很火就报计算机，金融挣钱多，就要报金融，完全是盲人摸象，不少家长，甚至根据几十年前对大学的认知，去选学校选专业。

报志愿这件事，大多数家长和老师，都只能起到负面作用。他们并不了解很多职业的细节和复杂性，学新闻就是要做记者，学编导就是做导演，其实学新闻的还要写广告文案、犄角旮旯的软文硬广，学编导的可能一辈子当不上导演，这都是你未来职业的一部分，选择性看到行业顶端的人最好的一面，未来从业过程中，最容易感受的就是痛苦，最容易做出的就是逃离的决定。

城市>学校>专业。

这个原则是选择志愿的黄金法则，很多人都提到过，但是并不是所有人都懂其中的商业逻辑。

这个排序反映的是平台的重要性。

城市是最重要的平台，大城市的平台是小城市无法匹敌的。很多新鲜的事物，领先时代的发明，新型的服务模式，都率先在大城市出现，发展。我常常说一句话，大城市就是文明的高地，小城市就是文明的边疆，这种平台的差异造就了一个结果，很多工作机会，在大城市涌现的时候，小城市还闻所未闻。

我无意冒犯很多人出生的城市，因为我也是小城市出生，但是，大城市越来越集中所有的资源，是一个全世界都存在，所有聪明的政治家、经济学者和社会学者都无法改变的问题。资本、高质量消费品、信息、甚至高颜值的美女和好身材的帅哥，都向大城市流动，甚至只在大城市出现。

普通人获得商业价值的一个重要方式，就是信息差，在大城市，才能站在信息高地上。

选择了大城市，就是给自己选择了更多的可能性，即使有一天退回小城市，也具备了远超小城市同类的信息差。

其次是学校。

大多数大公司，选择人才的时候，只看你的毕业院校，甚至只看本科院校。更好的院校，就是更好的平台。所以学校牌子，非常重要。

我以前觉得985不重要，可是真的到了社会上就发现，学校牌子给你的方便还是非常多的。大部分国企和私企的HR，其实没有兴趣搞清楚你的专业，除非你的专业是极度不对口的农林之类，否则没有人会卡你，卡你的就是你的学校的牌子。

主要还是本科的牌子，这就是高考志愿的重要性。

人就是在这时候分档的，这也就是高考成绩的重要性。硕士、博士这些学位，只对学术界有用，对企业的价值加成不高，大部分的企业非技术岗位，本科足够胜任，经验比学历更重要，而且通常更便宜，5000招个优秀的本科生绰绰有余，招一个硕士可能就跟硕士的期望有点不符，招博士博士就该有心理落差了。所以，干脆不如直接招优质本科生。

而且有一点，大部分HR对211、985其实并不了解，越是体制内越是不了解，其实就是看名气。

所以名校的光环真的有用，未来是可以用真金白银兑换的。

成绩好的同学可以偷笑了，但是成绩不好，又想上名校怎么办？

其实我们可以反向利用名校光环的漏洞。

我想问一个问题，什么叫名校？清北交复，这是名校，还有全国10所top3，15所top5，30所top10，固然是名校。但是这并不是名校的全部定义。

你要让上海人来说，上海财经大学绝对是顶级名校，你要让广东人来说，华南理工大学就是顶级名校，但是我见过上海财经大学，在北方被当成野鸡大学三本，华南理工大学，被认为是二本院校。你在我们「荷兰」，河南大学就是顶级名校，但是出了河南，就没有人太认这个学校。

这其实就是信息迷雾，名校是有地域性的。大多数人的认知有限，他们只会选择当地耳熟能详的地域性名校。

所以，我这里建议报考志愿的时候，想清楚你未来要去哪个地区工作，你要去北京天津北方地区，你就早点报北方的知名院校，你要在上海工作，你报上海大学，可能比你报兰州大学还有用，你要去广州工作，报华南理工，暨南大学，绝对比你报哈尔滨工业要方便，可能分数还要低。

还有一种，就是行业名校，你报考的院校，在行业内有深厚的底蕴，也就让你如鱼得水。比如政法类的五院四系，中国政法大学、西南政法大学、西北政法大学、中南财经政法大学和华东政法大学，还有北京大学法律系、人民大学法律系、吉林大学法律系、武汉大学法律系。

可以看出来，西北政法大学、中南财经政法大学、西南政法大学，跟其他几个难度根本不是一个档次，你要靠近北大、人大的法律系，还是中国政法大学是很难的，这时候，你就可以考虑其他法律类名校。

同样，北邮虽然不是什么top几的名校，但是最赚钱的计算机专业，北邮的学生半天下，基本就是质量过硬的标志。选择这些行业名校，就是站在巨人的肩膀上，要知道，你的路如果全要你自己走是很难的，你的前辈的师兄师姐，这些能干的校友们，给你开辟的路径，就是所谓的行业名声，他们的道路就是你的道路，跟着他们就是站在巨人肩膀上。

报名校的好处还一个就是，一般越是这种有点名气的学校，对你的限制越不严格，学校是一个平台，你专业没有报好，你还可以搞第二专业，搞创业，而很多学校，连这个平台都不给你。

最不重要的其实是专业。

但是，很多人还是在报考志愿时候犯错。

这里升老师要提醒的是，不要去扰乱市场，不要试图去混淆市场定价。

什么叫混淆市场定价呢？简单来说，就是2种行为。

报冷门、报新兴专业。

总有家长和学生想，我考的不理想，但是我不甘心，我报一个冷门专业，几年以后，说不定就成热门了，或者我报一个有前景的专业，比如动画，比如新媒体，几年以后我孩子就吃香了。

报冷门，如果是为了挤进名校，是可以的，怕就怕心存侥幸，盼着风水轮流转，专业重新变成热门，我告诉你，没有这种可能，一个专业成为冷门，是有时代的大趋势和科技发展规律的，这不是股票，有板块轮动。

冷的，只会大概率更冷，热的，大概率还会更热。

不报冷门，很多人理解，但是为什么不报新兴专业，很多人不理解。

因为要开设一个新兴的学科，是要很多人才储备的，思考一个问题，人从哪来？教师从哪来？大家可以看看，名校开设一个新专业，是非常慎重的，要有了很多学术研究成果才会开设，这种一窝蜂开设新专业的通常都是野鸡大学，开设这种新专业的目的只有一个，骗钱。

比如说新媒体专业，一共出现才6-7年时间，行业还在红利期，我们这些真正懂新媒体的人，会放着高额的利润不要，去个破野鸡大学当个青年教师，给几十个学生讲课吗？显然不会嘛。

而且新媒体的原理，其实跟传播学的原理没有区别，这些开设新专业的学校，无非是新瓶装旧酒。很多人选这种专业，往往是觉得更有针对性，其实远不如找一个老牌院校的老专业，学一些基本的知识更可靠。

这就是升老师要告诉大家的报志愿的选专业逻辑，选什么？

选基础设施专业，选底层逻辑专业。

想学新媒体，就选传播学过硬的专业院校。

理科的底层逻辑是数学，文科的底层逻辑是哲学，所有商科的基础都是经济学，如果可能，建议你选这种偏基础设施的学科，学基础设施学科的好处是，任他风吹雨打，我自岿然不动。

这个世界一直在变，但是底层逻辑是不变的。

大学最重要的，是打好你的基础，构建你的知识系统，丰富你的人格，让你成为一个更好的人，各种应用技术的发挥，都是建立在你是一个更优秀的人的基础上的，基础学科，能让你弄懂社会的底层逻辑，成为这个时代的基础设施。

打好基础之后，你想学什么专业都可以。

数学真正学得好的人，去搞计算机，去搞程序，没有混得不好的。

所以，我建议，慢一点，既然世界的大环境如此，不妨慢一点，给自己一点耐心，给时代一点耐心，要以成为一个时代基础设施的雄心，去选择自己的未来。

以上种种，都应该退让给你的热爱，你的天赋。

所有的功利的选择，都是基于现实世界的一种趋利避害。但是，如果你真的有自己热爱的事业，你有自己远超于常人的天赋，请务必坚持下去。

只是这种热爱，一定不能是因为这个专业赚钱多，有名气，你父母或者有个什么亲戚可以依靠，以现在时代的发展，未来什么行业会存在，什么行业会消失，一切都还待定。

你因为热爱和天赋迸发的能量，才是最不可忽视的，重要的永远不是学什么，而是怎么学。以学习的结果论，无论是名校还是三本大专，所有的课程设置都是滞后的，所有的专业和社会都是脱节的，但是这不代表学习没有用，这不代表你学了一门完全用不上的课程就没有用。

屠龙术不会没有用，能屠龙的人，自然可以屠鸡屠狗。

重要的是学习的过程，学习的方法，选择你热爱的和你天赋所在的志愿，你会更有激情。

如果可能，选择需要创意的志愿。

我知道，很多人跟你说过，工科好找工作，学一门技术，好生存。

但是，说这样话的人，一定没有考虑过，技术被淘汰了会怎么样？实际上一门应用技术，越专门，越特殊，在开始进入社会时，越具有优势，但是也越容易被淘汰，学一门技术，然后吃一辈子的时代过去了。

学一门技术，然后在30岁被迫学一门新技术，去跟年轻人竞争，才是大多数技术人员的宿命，35岁魔咒是很多技术人员包括程序员在内无法摆脱的魔咒。

学应用技术，很容易让你成为工具本身，而工具，是会被淘汰的。

这也就是我为什么建议多学基础学科，多选自己热爱的专业的原因。这里我再建议大家，多选需要创意的学科，选更像「人」的学科，人工智能时代就在不远的未来，更像人，更需要创意，你才不会被取代。

做个人，不要做工具。

不要想做永远在潮头上的人，不要想能抓住所有风口，天下风云出我辈，我们就是风，我们就是云，我辈不用总是乘风破浪，我辈就是风浪，未来总是属于浪漫的人。

什么是浪漫的人？浪漫就是守得云开见月明，浪漫就是坚持做长期的事。

## 16: 20250618-220302

中国古人发现的“天下大势，合久必分，分久必合”，才是世界的真相。

大概以美国总统威尔逊在巴黎和会上提出的“民族自决”理念为转折点，世界开始了“合久必分”。从最初的几十个国家，到现在，已经分化出将近200个国家级政治体。

接下来该“分久必合”了。那些分出去的国家，将以这样那样的方式整合起来。真正意义上的国家级政治体，数量将减少。那些乱七八糟的小国，没必要存在，也没条件存在。

但是，关于“整合”的政治理论，还几乎是空白。大行其道的，是“国家领土主权神圣不可侵犯”“战争就是邪恶”“所有国家不分大小一律平等”等过时且虚伪的理论。

世界需要整合的政治观念。中国的“天下”“大一统”政治观念，到了大显身手的时候了。

诸位学人，要努力啊。

~

