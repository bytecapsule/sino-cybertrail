# 2025-09-04

我对于小模型最感兴趣的是成本。

如果小模型可以完成任务，那么成本就会很低，就可以大规模使用。

但是在综合复杂任务上，小模型的性能不佳，很多只是玩具。

只有在专用任务上，小模型才能发挥优势。

翻译，其实是一个挺合适小模型的场景。

网易前面推出过一个小模型，大概是14B，效果很好，但是却是闭源的。

阿里也推出了Qwen-MT的翻译模型，阿里开源了很多，但是这个模型却是不开源的。

这次腾讯把他们的翻译模型开源了，7B参数，普通机器也能跑，不需要太大的显卡。

市场竞争真激烈，真是有点空隙，别人就钻进来了。

阿里就这个不开源，腾讯就把这个开源了。

混元翻译模型由翻译模型 Hunyuan-MT-7B 和集成模型 Hunyuan-MT-Chimera 组成。

翻译模型用于将源文本翻译成目标语言，而集成模型则集成多个翻译输出以产生更高质量的结果。

它主要支持 33 种语言之间的相互翻译，其中包括中国的 5 种少数民族语言。

主要特点和优势

在WMT25竞赛中，该模型在参加的31个语言类别中，有30个类别获得第一名。

Hunyuan-MT-7B在同规模机型中实现行业领先性能

Hunyuan-MT-Chimera-7B 是业界首个开源翻译集成模型，将翻译质量提升到新台阶

提出了一个全面的翻译模型训练框架，涵盖预训练→跨语言预训练（CPT）→监督微调（SFT）→翻译增强→集成细化，为类似规模的模型实现最先进的（SOTA）结果。

模型地址：huggingface.co/tencent/Hunyuan-MT-7B
