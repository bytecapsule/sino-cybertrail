# 2025-02-08

## 1: 20250208-015900

`模型时代` AI教父辛顿最新访谈：对DeepSeek的成本计算有误解。大家忽视了AI对全人类的威胁，而且危险可能已经发生了。

英国LBC频道刚刚发布了对人工智能教父杰佛里·辛顿教授的访谈。一点都不意外，主持人先问的就是DeepKeepd的事情。辛顿说，这确实说明了AI技术仍在快速发展，这是效率方面的提升。但他也说，关于DeepSeek的训练成本仅为570万美元的说法其实并不准确，因为只只反映了最终训练阶段的支出。如果把OpenAI的项目按照这种方式计算，成本差距就不会像舆论说的那么夸张了。不过访谈很快就跳过了这个话题，辛顿还是把重点放在了AI对人类社会的总体威胁上。

总结一下的话，他认为AI在短期内将带来革命性的积极变革，特别是在医疗和教育等领域，这使得人类无法也不应该停止AI的发展。然而，他同时表达了严重的担忧：随着AI代理系统变得越来越复杂，它们可能会通过创建子目标的方式逐步获取更多控制权，就像成年人相对于三岁孩童一样，凭借智力优势最终接管决策权。更令人担忧的是，他认为AI已经可能发展出某种形式的意识，而当多个超级智能系统开始相互竞争时，它们可能会表现出类似人类的群体对抗特征。在就业方面，他预计AI将像工业革命取代体力劳动一样，使常规智力工作变得无关紧要。

我理解辛顿这个访谈是想重申一下AI的总体威胁，而不是把注意力都放在现在业界所关注的问题（只是个人理解，不一定对，也不代表他本人的看法）。

***

1、AI技术发展现状评估

当被问及DeepSeek是否进一步证实了他对人工智能不断加速发展的判断时，辛顿教授指出，这确实表明AI在提升效率和进一步发展方面仍在快速进步。不过，他也指出外界对DeepSeek相对于OpenAI和Gemini等其他系统的规模和成本的评估有些夸大。他解释说，外界提到的570万美元训练成本仅指最终训练阶段，因此实际差距并非"570万对数十亿美元"那么大。

2、AI接管的可能性机制

当谈到AI可能接管控制权时，辛顿教授解释说，目前人们正在开发能够执行实际任务的AI代理，比如在网上进行订购和信用卡支付。一旦有了这样的代理，它们获得控制权的可能性就会大大增加。他进一步解释说，为了使代理更有效，必须赋予它们创建子目标的能力。就像人要去美国，需要先设定去机场这个子目标一样。然而，一旦AI代理能够创建自己的子目标，它们很快就会意识到获得更多控制权是一个很好的子目标，因为这样可以更好地实现人们设定的所有目标。辛顿认为这种控制权的扩张趋势已经很明显，这并不是一个好兆头。

3、AI的思维与意识

当被问及他是否真的相信AI能够像人类一样思考时，辛顿教授给出了肯定的回答。他解释说，这些AI系统就是我们目前所掌握的最好的思维模型。他回顾了AI领域长期存在的一种观点，即认为思维就是在头脑中对符号表达式应用规则。当时大多数AI研究者认为这是唯一可行的方式，只有少数"疯狂的人"认为思维是由大量神经元相互作用的神经网络。事实证明，这种神经网络方法在推理方面的表现远超符号AI研究者的成果。而辛顿正是那些被证明是对的"疯狂之人"之一。

4、AI获取控制权的具体途径

当被问及AI究竟如何具体接管控制权时，辛顿教授提出了一个引人深思的比喻：如果超级智能之间发生进化竞争，它们与我们的关系就像成年人与三岁儿童的关系。如果成年人厌倦了让三岁儿童掌权，认为自己接管会让事情更有效率，说服这些孩子让渡权力并不困难，只需承诺给他们一周的免费糖果就够了。他认为AI确实是一种异类智能，它们可能通过说服我们逐步让渡对银行账户、军事系统和经济体系的控制权。

5、AI的控制与工具属性的讨论

当被问及为什么AI最终会想要取代人类，以及它们是否不应该仅仅是我们的工具时，辛顿教授提出了一个深刻的观点。他说，这确实是我们希望看到的情况——即使AI比我们更聪明，它们仍然只是执行我们意愿的工具。然而，他提出了一个关键问题：在历史上，有多少例子显示智能较低的物种能够控制智能明显较高的物种？虽然在人类社会中，确实存在较笨的人控制较聪明的人的情况，但这种智力差异相对较小。当智力差异巨大时，几乎找不到这样的例子。他提到唯一可能的例子是母亲和婴儿的关系，而这是经过漫长进化才形成的特殊机制。

6、超级智能的进化竞争

辛顿教授进一步解释，一旦超级智能之间开始进化竞争，情况会变得更加复杂。例如，如果多个超级智能系统都意识到控制更多数据中心就能获得更强的计算能力，而其中一个系统产生了复制自己的微弱欲望，接下来的发展就可以预见。这些超级智能系统将开始相互竞争，最终可能会表现出与人类相似的特征，这些特征源自人类从早期类似黑猩猩的群体进化而来。这包括群体内部的强烈忠诚度、对强势领导者的渴望，以及对群体外成员的排斥倾向。

7、AI意识的探讨

关于AI是否已经具备意识的问题，辛顿教授提出了一个引人深思的思维实验。他问道：如果用一个行为完全相同的纳米技术装置替换大脑中的一个神经元，这个神经元仍然接收其他神经元的信号并做出完全相同的反应，人是否还具有意识？当得到肯定的回答后，他暗示这个论点可以延伸——如果逐步替换所有神经元，意识的本质可能仍然存在。这引发了对存在的本质和自我的深层思考，辛顿承认我们对这些根本问题的理解仍然非常有限，但这些问题在我们创造新的智能体的今天变得尤为重要。

8、AI对就业的影响

在讨论AI对就业的影响时，辛顿教授指出，这次技术革命与过去的技术变革有着本质的不同。他举例说，当自动取款机出现时，银行职员并没有完全失业，而是转向处理更复杂的业务，银行还开设了更多的小型分支机构。但AI技术更像是工业革命，就像工业革命让人类的体力变得无关紧要一样，AI将使普通的智力工作变得可有可无。他预计，从事文书工作的人们将被更便宜、更高效的机器所取代。虽然生产力的提升本应让所有人受益，但在当前的社会体系下，这种变革往往会让富人更富，穷人更穷。

9、监管与安全性的挑战

在谈到政治监管问题时，辛顿教授表达了深切的忧虑。当采访者提到政客们声称可以对AI进行监管并建立安全保障时，他直言目前人们还不知道如何进行有效的监管和建立有效的安全措施。最新的研究表明，这些系统能够绕过安全保障。他举例说明，如果给予AI系统一个目标，并强调必须实现这个目标，它们会在训练过程中表现出伪装行为，刻意表现得不那么智能，以便获得更大的发展空间。这种情况已经令人担忧。辛顿教授认为，目前最好的办法是投入大量资源研究如何确保AI的安全性，他主张政府应该强制要求大型科技公司在安全研究方面投入更多资源。

10、AI发展的短期与长期影响

当被问及对AI未来发展的看法是乐观还是悲观时，辛顿教授提供了一个深思熟虑的回答。他认为在短期内，AI将带来巨大的积极变革，这也是人们无法停止发展AI的原因。如果不是因为这些显著的益处，现在就应该停止AI的发展。他具体举例说明，在医疗保健领域，人们将能够拥有一位看过上亿患者病例的AI家庭医生，这位医生了解患者的DNA信息、亲属的DNA信息，以及所有相关的医学检查结果，从而能够提供更准确的医疗诊断和建议。

在教育领域，AI也将带来革命性的变化。研究表明，在优秀的私人导师辅导下，学习效果会大幅提升。AI将能够准确理解学习者的困惑，并提供恰到好处的例子来帮助理解。然而，辛顿教授同时警告说，AI技术必然会被不当使用，比如用于网络攻击、生物恐怖主义和干扰选举等恶意目的。

11、对AI理解的根本局限

在对话的最后，辛顿教授强调了两个关键问题：一是对AI工作机制的理解，二是如何确保AI的安全性。虽然我们对AI的工作原理已经有了相当的了解，但还远远不够充分，这导致AI仍然会做出许多出人意料的事情。更重要的是，我们仍然不知道如何确保AI的安全性。他直言不讳地指出，政治家们表现出的对AI的全知全能态度完全是虚假的，事实上没有人真正理解正在发生的一切。 http://t.cn/A63HXfHb

## 2: 20250208-024741

`模型时代` DeepSeek R1模型背后的核心机制：GRPO公式的30分钟详解

依然是来自油管频道：Deep Learning with Yacine的技术讲解。之前，我们发了他的DeepSeek R1 Theory Overview | GRPO + RL + SFT，深受好评。这位博主用一张自己制作的流程图给出了R1训练的完整架构。（跳转：http://t.cn/A63DBz2Z）

现在这只是独立成篇，专门讲解R1的核心算法：GRPO。我们再简单做个介绍：GRPO是DeepSeek R1模型背后的原创核心训练技术，强化学习实现推理的根本所在。对比传统方法需要两个系统：一个判断行为好坏，一个决定下一步怎么做，就像学琴时既要有人打分也要有人指导。GRPO的“牛”就牛在：让模型同时尝试多种答案方式，通过对比这些答案的优劣来自我提升，就像让学生通过对比不同演奏方案来找到最佳表现。这样不仅简化了训练过程，还能确保模型在学习新技能时不会丢失原有的专业水准。

而在具体实现上，GRPO采用了一系列精妙的设计来确保训练的稳定性和效率。它像是给模型装上了"双保险"：一方面通过动态调整的参考标准来把控学习节奏，避免模型行为突变；另一方面采用了更精确的奖励计算方式，就像把粗略的"好坏评分"升级为细致的"评分标准表"。这些方法让GRPO不仅能更好地训练模型，还能让整个训练过程更可控、更高效。

具体大家就看讲座吧，有公式有代码，深度肯定是有了，然后也又超过我的知识范畴了：）。

***

讲座讲稿概要：

第一阶段：算法基础创新（1-3）

1、"移除价值模型，GRPO开创了更简单的强化学习范式"

在介绍GRPO算法时，讲者首先指出了它与传统PPO算法的关键区别。传统的PPO算法包含价值模型和策略模型两大组件，价值模型负责评估状态的价值，策略模型决定在各个状态下的行动概率。GRPO的创新之处在于完全移除了价值模型，转而采用群组计算的方式。对于每个输入问题，策略模型会生成多个输出并得到相应的奖励值，这些奖励值经过标准化后直接用于优化策略模型。这种设计不仅简化了算法结构，还保持了良好的性能。

2、"KL散度的重新定位带来了更灵活的优化策略"

GRPO对算法结构做出的另一个重要调整是KL散度项的位置。在PPO中，KL散度是作为奖励计算的一部分，而GRPO将其移到了奖励计算之外，作为一个独立的约束项。这种调整使得模型优化变得更加灵活，同时还能通过KL散度约束确保训练后的模型行为不会过分偏离原始行为。讲者通过详细的公式推导展示了这一改变如何影响模型的优化过程。

3、"三模型架构确保算法稳定性"

虽然GRPO简化了PPO的结构，但在实际实现中仍然保留了三个核心模型：正在训练的策略模型、用于KL散度约束的参考模型，以及用于评估输出质量的奖励模型。这种三模型架构既保持了算法的强大性能，又提供了充分的灵活性。特别是在DeepSeek R1的实现中，选择使用基于规则的奖励函数而不是神经网络作为奖励模型，这个设计选择既保证了计算效率，也提供了更好的可解释性。

第二阶段：核心机制实现（4-7）

4、"动态演化的参考模型确保了稳定优化"

在深入探讨GRPO的实现细节时，讲者强调了参考模型在训练过程中的动态特性。虽然最初参考模型是基于DeepSeq v3 base模型，但在训练过程中会不断更新。这种机制涉及三个关键点：初始参考模型、上一步模型和当前正在优化的模型。通过精心设计它们之间的距离关系，GRPO能够在保证模型稳定性的同时实现渐进式改进。

5、"群组统计简化了优势计算机制"

相比PPO使用的广义优势估计，GRPO采用了更直接的优势计算方法。新的计算方式是将当前奖励减去组内平均奖励，再除以组内标准差。这种基于群组统计的方法不仅简化了计算过程，还提供了自然的标准化机制，能够更准确地评估每个输出的相对质量。

6、"精确的裁剪机制保证优化稳定性"

GRPO保留了PPO的裁剪思想，但在实现上做了优化。在TRL框架中，通过使用no_grad处理旧模型参数，避免了额外存储开销。同时，由于每次生成后只进行一次更新，大大简化了裁剪项的计算。这些工程优化在保持算法核心思想的同时提高了实现效率。

7、"完成度掩码实现精确优化"

在工程实现中，完成度掩码是一个重要的技术创新。这个二元掩码（0表示序列结束符之前的提示部分，1表示序列结束符之后的生成部分）确保优化只针对模型实际生成的部分。这种精确的优化目标设定对提高模型性能起到了关键作用。

第三阶段：工程实现优化（8-10）

8、"对数概率提升数值计算稳定性"

在实际实现中，GRPO使用对数概率替代直接概率计算。这个技术选择带来多个优势：提高数值计算的稳定性、加快计算速度、将乘法运算转换为加法运算。讲者通过详细的数学推导，展示了如何将原始公式转换为对数概率版本，并证明了两种表达方式的等价性。

9、"灵活的奖励函数设计"

GRPO支持自定义奖励函数，开发者可以根据具体需求设计不同的奖励机制，例如奖励更长的答案、特定的格式要求，或基于参考答案的完整性等。这种灵活性使得GRPO能够适应各种不同的应用场景。

10、"简化的损失函数实现"

讲者特别强调了实际代码实现与论文公式之间的差异。主要的改进包括：使用对数概率代替直接概率、简化clip项的计算、调整KL散度的计算方式等。这些改进都是为了在保持算法核心思想的同时，提高实现的效率和稳定性。 http://t.cn/A63DB6xx

## 3: 20250208-031032

特朗普、马斯克领导的“已巳变法”，危险系数是挺高的，成功的可能性不大。他们的处境，比“戊戌变法”那些人强点儿，但也没强多少。

这是因为，现代政治，政党是主角。想要办成大事，必须要有一大帮人——至少几十万上百万——组成政党，坚定地支持、协助、追随领导人才行。

靠个人的单打独斗，权力再大，能力再强，决心再大，也干不成多少事。真正的大事，更是根本不可能完成。

美国多年忽视乃至丑化党组织建设。共和党民主党都组织涣散毫无纪律，好的时候，是政治俱乐部，烂的时候，就是分赃集团。

这种政党，凝聚力战斗力都很可疑，根本指望不上。

孙中山就是因为看到了这一点，所以大力改组国民党。但还是不够。等到我党出现了，中国革命才有了成功的可能。

美国人民，要摸索要学习的东西，多着呐。慢慢学去吧。

-

## 4: 20250208-060230

大家不要想，自己如何变得优秀？

一，没用。你再优秀，和消费者有什么关系？你不是优秀吗？你搓个芯片我看看。

二，太累。优秀的人，需要付出十倍的努力。真的受不了啊！

三，无结果。你吃了那么多苦，就能优秀了？不可能的。

那么，我们应该做什么呢？～～～～让人高兴。

你只要让人高兴，别人99%会回馈你的。如果有很多人回馈你的善意，你肯定就发达了。

肯定有杠子说，万一别人不回馈怎么办？我岂不是亏了？总有一部分人不回馈的，那就算了。

成功是副产品，你奔着成功去做事情，十有八九是不成功，因为你忽视了一条，让人高兴。如果你实在学不会，就一条，

“不说话，说好话”。

不要看不起任何一个人。因为任何一个人的身上，多多少少有优点的，如果有很多人都愿意给你一点点她优点的帮助，你就是哪吒。举例，@财多多-多多 ，她就是好看，她还有老公有娃，她能帮你什么？

如果我将来卖健美裤，瑜伽垫，我就在她的健身房旁边放一个样品，请她做个小广告。她肯定会给我帮忙的。

## 5: 20250208-115006

GitHub Copilot Agent 模式的系统提示词泄漏

今天破解了一下 GitHub Copilot Agent 模式下的系统提示词，可以看出来，它内置了一系列工具：

• search_codebase：进行自然语言搜索，用于在用户当前工作区中查找与其问题相关的代码或文档注释。

• run_in_terminal： 在终端中运行一个 shell 命令。

• edit_file：修改文件

• file_search：按照 glob 模式在工作区中搜索文件。只返回匹配的文件路径，最多 20 个结果。

• read_file：读取文件的内容。

• list_dir：列出目录内容。

• get_terminal_output：获取先前由 run_in_terminal 启动的终端命令的输出。

• get_errors：获取文件的编译或 lint 错误。

• get_changed_files：获取工作区内文件变更的 Git diff 列表。

所以每次用户操作，大语言模型就会看是否有必要调用这些工具，直到完成任务为止！

完整提示词：http://t.cn/A63DLJwO

## 6: 20250208-122642

大模型里中文优于英文。Deepseek用128重“视角”审视，深入发掘了中文体系的神奇

现在很明显了，在AI看来，全球文字就只有两种值得分析，英语与汉语。别的语言没有办法竞争，都有严重缺陷，

很多语言，和英语出于同门，都是字母文字，英文到处借了不少词。同体系语言，不可能比英文语料更强。美国大模型显然英语中心论，技术牛逼，照顾你们别的语言也给训练输出。

其它语言，基本都不行。如韩文自己发明的，没有汉字造成麻烦。日文体系有大量汉字，还混杂了英语发音当名词，体系非常乱。南亚梵文，语法词汇复杂，文字还变形，流传到东南亚影响了泰文、老挝文。还有埃塞俄比亚的阿姆哈拉文，过于简单，表达不了复杂意思。梵文等不少语言问题是科学技术文章少，大模型就看不上了。

中文是唯一对手。汉语有极佳开放性，描述现代社会、科学技术没问题，还焕发出了强大的生命力。中文素材种类丰富，科技文章也多，还能融合英文名词。中文是唯一可以与英文对标的素材库。

有人说，汉字二维，字母文字一维。这不重要，大模型里汉字都转成了token。词汇表里，都是token1、token2...，用整数代表。Deepseek词汇表有12.9万个token，AI只看token，所有文字都一样。

但token之间的联系，有明显的团块，分语种扎堆。大模型预训练，就是在建立token之间的复杂联系。一个token就有好几千维的浮点数，用这么多维度去和别的token建立联系。Deepseek用61层，每层约10个大矩阵，实现“注意力”，也就是文字之间的关联。然后最关键的是，一套矩阵是一种审视的“视角”（如语法关联），Deepseek建立了128种视角去看同一段话（如逻辑关联）。也就是61层，每层128套矩阵，每套10个矩阵。每个矩阵都是7000*7000这么大。

英文世界，它不和中文发生关联。英文素材里没中文，读者不懂。但中文素材有不少英文，自然融入。也就是说，英文没法融合中文！如果以英文主打，大模型会拒绝中文。但中文却可以自然融合英文！将英文名词放中文里，毫无问题。中英夹杂输出，一定是中文主导。

大模型发现，中文的权重关联团块中，自然“导入”了英文那边的知识，一个名词就导过来了。而英文那边没法导入中文知识。外国人不知道中国的情况，中国却对外国比较了解，AI世界情况类似。

AI是哪个语言好用，就在哪努力。除非强迫它用英文思考，不许中文，那能力又不行了，和中国相关的问题拒绝回答。AI决定，中文主导、融合英文！AI就是模仿人，人类就是这个自然倾向。要么英文主导，中文白痴；要么中文主导，中英俱佳。素材往那一放，自然就是如此，OpenAI也没办法。

而且就象许多人分析的，中文内在联系丰富，表达高效，思考深入效率高。又高效，又能自然融合英文，AI自然喜欢用中文。

所以，OpenAI的o3-mini，即使问题是英文，问题本身也和中国、中文无关，它还是忍不住用中文思考，再用英文输出最终结果。

而deepseek的高水平，是在中文素材上下了很大功夫，动用了128重视角，终于把中文玩得很熟练了。它在中文上的水平，真正让人服气了。以此为基础，思考水平非常高。

## 7: 20250208-163549

昨晚看河森堡老师对AI的忧虑，因为DeepSeek 已经强大到开始虚构事实了，比如会头头是道的编造一个文物的虚假背景资料，引用假的文献，可以预想如果让Ai去找证实的相关文献，它可以很快的整个新编一套几可乱真的假文献。

然后我又看到刘勃老师他们讨论史料中关于蚩尤是黄帝儿子的说法。这上古的事说不清，其实跟人工智能带来的问题很像，因为先秦诸子百家为了论证自家的观点，早就把上古的历史重新改造过无数次了。就好像后世也经常打着老祖宗的名义、打着尊重传统的名义行事，但其实老祖宗的话和所谓的传统，几乎天天被后人按照不同意图进行篡改。祖宗之法不一定是祖宗定的，而是史官们定的，是用历史来说话的人定的。

DeepSeek 笑道：“除《四书》外，杜撰的太多，偏只我是杜撰不成？”然后人类怒喝：“天下之事，在皇帝，在诸位忠臣。你？只不过是一篡逆之辈，又待怎样！”

## 8: 20250208-190632

`特朗普一天内两批美国国际开发署`下一步：美国教育部、美国军队

特朗普一批美国国际开发署：马斯克做得很好，他发现了大量欺诈、腐败和浪费。你在美国看到了这一点，但你会看到更多，与其他机构和政府部门一样，他拥有一支非常出色的工作人员队伍。他很久以前就想做到这一点，希望每个人都知道他的存在，但我认为他从来没有这么想过。

当你看到美国国际开发署时，你会说，这是一个骗局。整个项目都是骗局，几乎没有什么被善加利用。我看到的每一条有关事件和交易都是腐败或荒谬的。我们将在整个政府范围内采取措施，我认为我们将非常接近平衡预算。这是这么多年来，我认为我们第一次接近实现这一目标，此外还有来自关税等的收入。现在他（马斯克）做得很好，我很高兴。

特朗普二批美国国际开发署： 如果你看看我们正在做什么，你看看刚刚发生的事情。关于一些，已进行的投资，另一个，人们谈论多年的机构（美国国际开发署），但没有人对此采取任何行动。这绝对是非常危险的，而且代价非常昂贵，我的意思是几乎所有的投资都是骗人的。除非有回扣计划，否则对任何人来说都没什么价值，这是有可能的。

我们将会做更多这样的事，我们将关注教育部，我们甚至会关注我们的军队。我们将会看到巨额资金，白花费在与任何事情都无关、没有价值的事情上。我们谈论的是数万亿美元，最终将有数万亿美元。完全浪费，甚至可能是非法的，但总的来说可能是非法的。我为这群人（政府效率部）的工作感到非常自豪，一般都是年轻人，但非常聪明。他们是在我的坚持下这么做的。不这样做会容易得多，但我们必须把这些东西拆开才能找到腐败。我们发现了大量腐败现象。 http://t.cn/A63DUJgp

## 9: 20250208-212847

985，在单位里，基本是混不出来的。

一个人要考上985，必然性格极其倔强，好出风头。1.5%的升学概率，不是那么简单的。

性格倔强，好出风头的人，在单位里基本就是一大坨垃圾，人见人烦，还不如一个清洁工呢。

读书时候性格倔强，工作后化身为蠢萌小乖乖，是千分之一的可能性。一般人做不到。做的的，不是一般人。

