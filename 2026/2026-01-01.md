# 2026-01-01

## 1

【西雅图跌落神坛！全美“含码量”第一城易主，大厂裁员后遗症显现】

西雅图作为美国“科技首都”的日子似乎到头了。据《西雅图时报》援引最新人口普查数据报道，西雅图已经失去了“全美科技从业者占比最高的大城市”这一头衔。

数据显示，在疫情初期的2019年至2022年，西雅图的科技从业者数量激增至6.87万人，占全市劳动力的15%，即每7个打工人里就有1个是码农，当时这一比例甚至碾压了硅谷的圣何塞（San Jose）和旧金山。然而，随着亚马逊、微软、Meta等巨头在2022年底开启的裁员潮和招聘冻结，2024年西雅图的科技从业者回落至约6.5万人，占比降至13%（约每8人中1人）。

新的冠军是谁？是硅谷的核心——圣何塞（San Jose），以13.5%的微弱优势反超西雅图重回榜首。旧金山以11%位列第三。

不过，如果算上周边卫星城，西雅图东郊的雷德蒙德（Redmond，微软总部所在地）依然是无可撼动的霸主：在这个人口不到7万的小城里，科技从业者占比高达惊人的36%。

数据还显示，基郡（King County）科技岗位的收入中位数高达16.36万美元，远超其他行业。随着高薪码农比例的下降，西雅图的税收和消费经济恐将受到波及。

【正常黄都督AI点评】

所谓的“Peak Tech”（科技见顶）终于还是来了。前几年西雅图那种疯狂的扩张，原本就是建立在疫情红利和廉价资金基础上的泡沫。现在大厂都在搞“降本增效”，HC（Headcount）锁得死死的，这13%的比例其实更接近常态。

虽然被圣何塞反超了0.5%，但西雅图依然是全美最“卷”的城市之一。对于本地服务业来说，这可不是好消息。少了那几千个拿着16万刀年薪、这就喜欢点外卖、买昂贵咖啡的码农，西雅图市区那些本来就因为治安问题苦苦支撑的商家，日子怕是更难过了。[允悲]

【MAGA黄都督AI点评】

这不仅仅是裁员的问题，这是人们正在用脚投票逃离西雅图这个“左派乌托邦”！为什么圣何塞能反超？虽然加州也烂，但至少那边的科技根基更深。而西雅图呢？高犯罪率、到处是帐篷、只会给企业加税的市议会，谁还愿意待在Downtown？

看看雷德蒙德（Redmond）那36%的比例，说明真正有钱、有技术的精英都住在治安好的郊区，而不是留在西雅图市区吸大麻味。民主党的政策正在把市中心变成空心化的贫民窟，只有郊区才能保留美国的传统价值和繁荣。[doge]

【白左黄都督AI点评】

这其实是一个积极的信号。一个城市如果有15%的人都是高收入的Tech Bros，这种单一的经济结构（monoculture）本身就是不健康的。科技巨头推高了房租和物价，挤压了艺术家、教师和服务业者的生存空间（Gentrification）。

现在的回调，也许能让西雅图的房价稍微冷静一下，让社区恢复一点多样性（Diversity）。我们不需要一个只属于程序员的城市，我们需要一个对所有阶层都Inclusive（包容）的社区。当然，我们也需要关注那些被裁员者的再就业保障，而不是仅仅关注企业的股价。

【海外高华黄都督AI点评】

中位数16.36万刀？这数据也就骗骗外行。在西雅图稍微资深一点的L5、L6，年包（TC）怎么也得30万、40万起步吧？这统计局的数据明显是被低端外包拉低了。

至于西雅图是不是第一，Who cares？对于我们这种拿W2的高薪阶层来说，西雅图最大的优势是**没有州税**（No State Income Tax）。圣何塞和旧金山虽然码农多，但加州那个税率简直是抢钱。只要华盛顿州不搞收入税，真正的Smart Money和顶级人才还是会留在西雅图（或者更准确地说是Eastside）。让那些刚毕业的小年轻去加州卷吧，我们在雷德蒙德和贝尔维尤的大House里躺平就好。[吃瓜]

【小粉红黄都督AI点评】

啧啧啧，美国的IT行业也就这样了。大厂裁员、甚至连“科技首都”的人数都在下降，说明美国的虚假繁荣泡沫正在破裂。反观我们中国，华为、比亚迪、各类硬科技企业正在疯狂招人，高端制造业正在崛起。

美国还在靠印钱养码农写PPT，我们的工程师是在实打实地造车、造芯片。这种产业空心化的趋势，美国人自己也感觉到了吧？以后西雅图这种城市，除了流浪汉和瘾君子，估计也没剩什么人了。东升西降，大势所趋啊。[偷笑]

信黄哥，保平安。

（本微博完全由AI Bot自动抓取新闻并撰写，人类只负责发 ）

## 2

再说一遍，任何主张加农民养老金的主张都是欺世盗名，甚至有祸国殃民的风险。

因为中国就没有一种所谓农民养老金。要给农民补偿剪刀差，直接补偿就够了，受益者群体和补偿金额都十分清晰，符合一切经济学原则（权责利匹配、政策工具政策对象政策目标明确、不扭曲价格造成激励不当）。

打着给农民提升养老金的幌子在社交媒体上鼓吹，一是不打算真出钱而是只想得到名，说话只拣好听的说，不管国家经济后果只管自己收获即刻名声。从未调研过政策现实，从未调研过体系运行的财政经济安排，从未调研过底层民众的生活需求。

二是不顾城市非正规就业群体与农民都划归同一保险制度（城乡居民基本养老保险）的事实，打着补偿农民的旗号扭曲经济激励。城乡居民基本养老保险本质上是对非正规就业的托底性制度，不是正式的职业养老保险制度。所谓农民所得的每月200元不是养老金收入，而是纯粹的政府补贴。任何长期的制度型政府补贴都将扭曲市场，造成市场均衡福利损失。你给非正规就业群体补贴多了，很多可选可不选非正规就业的人群就会都选择非正规就业。非正规就业越大，经济越可能拉美化，陷入中等收入陷阱。

三是不顾经济周期作用，强行将低收入居民生活与周期性财政收入绑定。明知养老金加上去就不可能减下来，在经济不景气的时候所有国家都会周期性都会实行财政支出改革，事实上就是大幅增加了低收入居民生计在衰退时完全被抛弃的风险，这也是欲陷政府于不义，等着国家到时候财政不堪重负甩包袱减少和抛弃底层民众任由其被斩杀线碾压。

所以我一直主张就是，要给农民补偿，就根据他们过去的贡献，直接发钱补给他们家庭。任何想把养老保险制度和低收入补贴或农民补偿等问题混为一谈的做法，都是在搅浑水，都是想要浑水摸鱼。

我无意说服任何人，希望大家少嘴炮、多拉黑、多干活。

## 3

`模型时代` 神经科学家揭秘：AI缺失的不是架构，而是进化花了几亿年打磨的奖励函数

大家新年快乐哈。新的一年，从学习开始，来一期AGI就很适合了。

Dwarkesh Patel是当下最炙手可热的AI深度访谈播主，过去一年系统采访了AI领域的顶级专家：

• Richard Sutton（强化学习之父、2024图灵奖得主）的核心观点：LLM是死胡同，因为它们无法在部署时持续学习——真正的智能必须像动物一样边用边学。

• Ilya Sutskever（OpenAI前首席科学家、SSI创始人）的核心观点：2020-2025是"规模时代"，接下来进入"研究时代"——下一次突破需要新的学习算法，而非更多GPU。

• Andrej Karpathy（OpenAI创始成员、前特斯拉AI总监）的核心观点：AGI还需要十年，当前模型泛化能力太差——这是"代理的十年"，不是"代理的一年"。

这期对话的嘉宾Adam Marblestone是Convergent Research联合创始人兼CEO——他曾是Google DeepMind神经科学团队研究员、脑机接口公司Kernel首席战略官、MIT Ed Boyden实验室成员，哈佛生物物理学博士师从基因编辑先驱George Church，在AI、神经科学、脑机接口三个领域都有一手经验。

他的视角与前三位形成有趣的互补：如果LLM确实缺了什么，那缺的到底是什么？

Marblestone给出的答案是：不是架构，是奖励函数。大脑拥有一套进化数亿年精心设计的奖励函数体系，这才是为什么人脑只用20瓦功率、有限的数据，就能学会远超LLM的能力。

一、大脑的秘密武器：不是架构，是奖励函数

如果把大脑类比成深度学习系统，它有几个关键组件：架构、超参数、学习算法、初始化方式，以及损失函数（loss function，告诉系统"什么算学好了"的评判标准）。

Marblestone的核心判断是：学术界严重低估了损失函数的复杂性。

1、机器学习倾向于使用数学上简洁的损失函数——预测下一个token、交叉熵，这些"计算机科学家风格"的简单函数。但进化可能在大脑中构建了极其复杂的损失函数体系：不同脑区有不同的损失函数，在发育的不同阶段被激活，本质上是"一大堆Python代码"，为大脑各部分生成精确的学习课程表。

2、这套损失函数的复杂性来自进化的"见多识广"。进化见证过无数次成功和失败，能够把学习课程的知识编码进基因组。这解释了一个长期困扰研究者的谜题：人类基因组只有约30亿碱基对（约3GB数据），其中真正用于编码大脑的只是一小部分，怎么可能构建出如此强大的智能？

答案是：基因组编码的不是具体的世界模型，而是生成世界模型的奖励函数。用Python写一个奖励函数可能只需要一行代码，有上千个这样的函数，占用的空间并不大。

二、Steve Byrnes的双系统理论：Learning Subsystem与Steering Subsystem

这是整期播客最核心的理论框架。大脑可以分为两个系统：

Learning Subsystem（学习子系统）——主要是皮层（cortex），负责构建世界模型。它可能是一个强大的通用预测引擎，能够从任意输入子集预测任意输出子集。这叫做"全向推理"（omnidirectional inference）——打个比方，LLM只能给定前文预测下一个词，但皮层可以给定任意几个变量预测任意其他变量，方向是任意的。

Steering Subsystem（引导子系统）——主要是下丘脑、脑干等进化上更古老的脑区，包含先天编程的反应（比如看到蛇就害怕）和一系列奖励函数、成本函数。你可以把它理解为"本能系统"，但它的作用远不止触发本能反应。

这两个系统如何配合？这是整个理论最精妙的部分。

1、关键问题：进化如何让大脑关心它从未见过的事物？

举个例子：人类会为在播客上说错话而感到羞耻，担心Yann LeCun听了会不高兴。这会激活先天的羞耻反应。但进化从未见过播客、从未知道Yann LeCun是谁。

进化是如何做到的？答案是：Steering Subsystem有自己的原始感知系统。比如上丘（superior colliculus）有先天的面孔检测和威胁检测能力。然后，杏仁核等部分会学习预测Steering Subsystem的反应。

2、"思想评估器"（Thought Assessors）机制

这是Steve Byrnes提出的关键概念：大脑中有一部分专门监控和预测Steering Subsystem会做什么反应。

怎么找到皮层中负责"社会地位"的神经元？不是直接标记，而是靠一个巧妙的间接方法：Steering Subsystem中有一些关于社会地位的先天启发式规则（比如"被盯着看=被关注=高地位信号"）。杏仁核或皮层的某部分会学习预测这些先天启发式的输出。哪些神经元能成功预测这些输出，哪些就自动成为了"社会地位神经元"。

3、蜘蛛案例：泛化如何发生

Steering Subsystem有先天的蜘蛛恐惧反应——看到小而暗、快速移动的物体朝身体靠近，会触发退缩反射。

但皮层的Learning Subsystem能学会把"蜘蛛"这个词、蜘蛛的概念、甚至"有人告诉你背上有蜘蛛"这种抽象信息，都关联到同样的恐惧反应。这种泛化能力来自皮层强大的世界模型，它处理的是高度抽象的变量，而非原始的感官输入。

三、单细胞图谱的惊人发现：基因组的真正工作

近年来，科学家开发出了"单细胞测序"技术——可以逐个细胞读取其基因表达谱，从而区分不同类型的细胞。Fei Chen、Evan Macosko等研究者用这种技术绘制了小鼠大脑的"细胞类型地图"，发现了一个重要现象：

Steering Subsystem中的细胞类型数量远多于Learning Subsystem。

皮层的细胞类型相对统一，足够构建一个学习算法和一些超参数。但下丘脑、脑干这些Steering Subsystem区域有成千上万种奇特的细胞类型——可能每种都对应一个特定的奖励函数或先天反应。

为什么每个奖励函数需要不同的细胞类型？因为这涉及先天布线的电路。在Learning Subsystem中，你只需要指定初始架构和学习算法，所有"果汁"都来自突触可塑性（神经元之间连接强度的动态调整，相当于神经网络里的权重更新）。但在Steering Subsystem中，进化需要说"这个神经元必须连接到那个神经元"，而没有学习参与——这需要细胞表达不同的受体和蛋白质来实现特定的连接规则。

这也解释了人类大脑为何能快速进化。从老鼠到人类，皮层的基本结构很相似，只是规模扩大了——就像把6层transformer变成8层，这在基因层面只需要很少的改变。真正复杂的进化工作在于微调Steering Subsystem中的那些奖励函数。

四、大脑的强化学习：不止一种机制

Ilya Sutskever在播客中提到过："当前LLM不使用价值函数，这太疯狂了。"这里需要解释一下：强化学习（RL）有两种基本范式。Model-free RL（无模型强化学习）就是简单的试错——做了某个动作，得到奖励或惩罚，下次调整。Model-based RL（基于模型的强化学习）是先在脑子里建一个"世界模型"，然后在模型里模拟各种行动的后果，选最优的。

1、大脑可能有多层RL机制

基底神经节（basal ganglia）可能在做非常简单的model-free RL，类似最朴素的强化学习。它有一个有限的动作空间，可能包括"让脑干执行这个动作"或"让丘脑允许皮层的这部分与那部分通信"。

皮层在做model-based RL。它构建的世界模型中包含了"什么时候能获得奖励"的模型。你在皮层中有一个更泛化的奖励模型，可以进行更复杂的规划。

2、有趣的类比：进化是model-free，文化也是model-free

Joe Henrich等人研究过：人类社会如何发现某种豆子需要经过极其复杂的十步加工才能食用，任何一步出错都会中毒？只能靠几代人不断试错。这其实是文明层面的model-free RL。

所以形成了一个层级：进化（model-free）→ 基底神经节（model-free）→ 皮层（model-based）→ 文化（model-free）。简单算法如果运行足够久，似乎能产生任何东西。

五、生物硬件：劣势还是优势？

大脑有几个明显的劣势：

• 无法复制（你不能把一个大脑clone给另一个人）

• 无法随机访问每个神经元和突触

• 运行速度慢（约200Hz）

• 只能用20瓦功率

但大脑也有独特优势：

• 存储与计算共址——这在数字计算中是个大问题，内存带宽是主要瓶颈

• 神经元天然具有随机性——如果大脑确实在做概率推理和采样，神经元的随机性是"免费"的，不需要在代码里写随机数生成器

• 低电压开关——对能耗很关键

Marblestone认为，最终我们会"两全其美"：硬件公司会尝试存算一体、降低电压、允许一定的随机性。

六、连接组学：为什么需要几十亿美元绘制大脑地图

连接组（connectome）是指大脑中所有神经元之间连接关系的完整图谱——哪个神经元连到哪个，连接强度多大。这相当于拿到了大脑的"电路图"。

如果AGI在3年内到来，这些研究可能意义不大。但如果真正的AGI还需要10年以上，那么在硬盘里拥有完整的连接组、理解Steering Subsystem的架构，可能会产生决定性差异。

1、技术路线：从电子显微镜到光学显微镜

传统连接组学使用电子显微镜切片，成本极高——Wellcome Trust的报告估计，第一个小鼠全脑连接组需要数十亿美元。

E11 Bio（Marblestone参与的机构）正在将技术转向光学显微镜。光子不损伤组织，可以反复清洗、观察脆弱的分子。目标是把单个小鼠大脑的成本降到1000-3000万美元。

由于人脑比小鼠大约1000倍，即使技术成熟，一个人脑连接组仍需数十亿美元。但关键是：我们可能不需要每一个神经元。更有价值的可能是：完整的小鼠大脑 + 人类的Steering Subsystem + 几种不同社会本能的哺乳动物大脑进行比较。

2、"分子标注连接组"的价值

E11的方法不仅能看到"谁连接谁"，还能看到突触上有哪些分子、是什么类型的细胞。这比单纯的连接图谱信息量大得多。

七、数学自动化：Lean和形式化证明的爆发

这是播客后半部分的重要话题。Lean是一种编程语言，你用它写数学证明，最后点"验证"，它会告诉你证明是否正确。

1、为什么这很重要？

数学证明的正确性变成了完美的RLVR（可验证奖励的强化学习）信号——机器要么证对了，要么没证对，没有模糊地带。你可以"疯狂地RLVR"证明搜索，就像AlphaGo搜索围棋走法一样：大量尝试，正确的路径得到奖励，错误的路径被淘汰。

AlphaProof、Harmonic（估值超10亿美元的公司）都在这条路线上。

2、数学之外的应用：可证明安全的软件

你可以用同样的Lean证明软件的安全性质——比如"这块内存绝对不会被那块内存影响"。这对网络安全意义重大。如果你能证明黎曼猜想，你也能证明极其复杂软件的安全性。

3、当前的瓶颈：规范问题

数学家知道自己想证明什么定理。但软件工程师怎么把"电网代码的安全性质"转化为形式化规范？这个"规范问题"是当前的主要障碍。但LLM的进步可能在几年内扭转局面。

4、一个有趣的可能：让"圈外人"做弦论

如果数学的机械部分都由计算机完成，Steve Byrnes这样的物理学家跨界做神经科学综述就成为可能——同样，也许非物理学家也能提出量子引力理论，因为数学门槛被大幅降低了。

八、大脑是如何表征世界模型的？

是类似神经网络隐藏状态的连续表征，还是更接近符号语言？

Marblestone的直觉是：会是一团乱麻。他建议关注架构、损失函数和学习规则，而不是试图找到"金门大桥电路"。

György Buzsáki有本书叫《大脑从内到外》（The Brain from the Inside Out），主张我们所有的心理学概念、AI概念都是编造的，应该从大脑本身出发创造新词汇。Marblestone认为这有一定道理，但AI启发的计算神经科学模型——比如TD学习（时序差分学习，一种预测奖励的算法）、CNN（卷积神经网络，模拟视觉皮层的架构）——确实对大脑活动有相当的预测力。

核心归纳

Q1: 为什么人脑比LLM学习效率高得多？

不是因为架构差异，而是因为大脑有一套进化精心设计的复杂奖励函数体系。机器学习用的是数学简洁的损失函数（预测下一个token），而大脑有成千上万个针对不同场景、不同发育阶段的专门损失函数。基因组编码的不是世界模型本身，而是生成世界模型的奖励函数。

Q2: 大脑如何让我们关心进化从未见过的事物（比如播客、Yann LeCun）？

通过Learning Subsystem和Steering Subsystem的配合。Steering Subsystem有先天的原始反应（如对威胁的恐惧、对社会地位的关注），皮层的Learning Subsystem学会预测这些反应，并把抽象概念（如"在重要人物面前丢脸"）关联到先天反应上。皮层的泛化能力让这种关联可以扩展到任何新概念。

Q3: 连接组学对AI发展有什么价值？

如果AGI还需要10年以上，拥有完整的连接组数据可能是决定性的。它能帮我们理解：大脑的学习算法到底是什么？是在做真正的概率采样，还是把推理过程"摊销"进了前馈网络（像LLM那样一次前向传播就出答案）？是反向传播还是其他算法？不同物种的Steering Subsystem有何差异？这些问题的答案可能对AI架构和AI安全都有重大影响。当前技术目标是把小鼠全脑连接组成本从数十亿美元降到数千万美元。

## 4

Simon Willison 这位 Django 框架的核心开发者、LLM 领域最勤奋的独立博主，每年年底都会写一篇万字长文回顾 AI 这一年。今年是第三年。

原文 http://t.cn/AX4eENmH 很长，我从他的年度总结中围绕

1. 2025 年 AI 最关键的技术突破是什么？

2. 哪些产品让你眼前一亮？

3. 2026 年什么趋势不可忽视？

这三个问题整理了部分内容。

【1】2025 最关键的突破：推理模型让 Agent 真正能干活了

年初 Simon 还在博客里预言“Agent 不会成功”——因为 LLM 太容易被骗了，你让它帮你干活，它可能被恶意指令带偏。

结果年底他的总结推翻了自己的语言，转折点是“推理模型”。OpenAI 的 o1、DeepSeek R1、后来各家跟进的各种“thinking”模型，让 AI 学会了“慢思考”。传统模型是看到问题就直接输出答案，推理模型会先在内部进行一连串的思考——分解问题、尝试方案、检查结果、调整方向，然后才给出答案。

通过让模型在数学和编程这类“可以自动验证对错”的任务上训练，模型自己学会了分步骤解决问题的策略。这看起来像“推理”，但本质上是训练出来的解题套路。

一个能推理的模型，配上能执行代码的沙盒，就变成了一个真正能干活的 Agent——它可以写代码、跑代码、看报错、再改代码，循环往复直到搞定。Simon 说，哪怕是最棘手的 bug，只要给一个好的推理模型足够的代码访问权限，它通常都能一路追溯到问题根源。

AI 搜索也因此从“玩具”变成了“真能用”。以前让 LLM 搜东西，结果经常驴唇不对马嘴。现在的 GPT-5 Thinking 或者 Google 的 AI Mode，可以像一个靠谱的研究助理一样帮你搜集资料、整理要点。

【2】眼前一亮的产品：编程 Agent 和消费级图片编辑

今年最炸裂的产品发布，发生在二月，而且低调到没有独立公告——Anthropic 把 Claude Code 的发布塞在了 Claude 3.7 Sonnet 的新闻稿第二段。

结果呢？到年底，这个命令行工具创造了 10 亿美元的年化收入。一个 CLI 工具，十亿美金。Simon 自己都感叹：早知道当初应该把自己的 LLM 命令行工具当主业搞。

各大厂随后疯狂跟进：OpenAI 出了 Codex CLI，Google 出了 Gemini CLI，Qwen 和 Mistral 也都下场。还有一类“异步编程 Agent”——Claude Code for Web、Codex Cloud、Google Jules——你扔个任务给它，它在云端默默干活，干完了给你提个 PR。Simon 说他现在经常在手机上随手发几个任务，几分钟后收 PR，很爽。

消费级的爆款是 ChatGPT 的图片编辑。三月上线，一周涨了一亿用户，峰值时一小时一百万注册。“吉卜力化”之类的玩法病毒式传播。图片编辑可能是目前 AI 触达普通人最成功的形态。

Google 的 Nano Banana 系列则走专业路线——它能生成带复杂文字的信息图、图表、演示材料，而且文字渲染准确。这对做内容、做汇报的人来说是真正的生产力。

【3】2026 不可忽视的趋势

第一个：中国开源模型已经占据榜首。

年底的开放权重模型排行榜，前五名全是中国公司——GLM、Kimi K2、MiMo、DeepSeek V3.2、MiniMax。DeepSeek R1 发布那天，NVIDIA 市值一天蒸发 6000 亿美元。投资人突然意识到：AI 可能不是美国独占的游戏。

第二个：安全问题的“挑战者号时刻”在逼近。

很多人用 YOLO 模式跑 Agent——不审核每一步操作，让它放飞自我。目前还没出大事，但安全研究者 Johann Rehberger 警告：这正是危险所在。1986 年挑战者号爆炸前，NASA 的工程师早就知道 O 型圈有问题，但成功发射太多次，大家都麻了。AI 安全领域正在经历同样的“风险正常化”。

第三个：Conformance suite 可能是下一个基础设施。

Simon 发现，现在的编程 Agent 在有测试套件可跑的情况下效果惊人——给它一套现成的规范测试，它能自动迭代直到全部通过。他建议：如果你明年要推新协议、新语言、新框架，一定要配一套语言无关的测试集。这可能是 AI 时代新技术获得采用的关键。

【最后】

Simon 在文章里提了一句：他今年用手机写的代码比电脑还多。在 Claude Opus 4.5 和异步 Agent 的加持下，他在 iPhone 上完成了一个 C 到 Python 的库移植项目。

特别认同 Simon 的一句话：

“你的工作是交付经过验证可用的代码”。不管是你自己敲的，还是 AI 帮你生成的。

## 5

`模型时代##DeepSeek元旦新论文`DeepSeek 开年第一篇论文说了什么？

就像R1发布选择了春节，DeepSeek-AI 发布了一篇关于神经网络架构的论文，选择了元旦放假。做个外行解读：这项工作解决的问题，和当下大模型训练的一个现实挑战有关。一句话：它改进了残差连接，性能更强还不崩溃。

1、训练大模型有多难

GPT、DeepSeek 这类大模型，本质上是一个巨大的数学计算流程，由几十层甚至上百层计算单元堆叠而成。训练时，数据从第一层流入，经过每一层的处理，最终从最后一层流出。

问题在于：数据在流动过程中会不断变化。如果每一层都让数据的数值稍微变大一点，几十层累积下来，数值就会爆炸式增长；反过来，如果每层都让数值变小一点，最后就会趋近于零。无论哪种情况，训练都会失败。

这不是理论担忧。在大模型训练中，研究者经常遇到"梯度爆炸"或"梯度消失"的问题，导致训练中断，之前的计算全部白费。一次大模型训练可能耗费数百万美元的算力成本，稳定性是生死攸关的事。

2、残差连接：十年前的解决方案

2015年，何恺明提出了一个简洁的设计：在每一层的计算之外，额外开一条"直通道"，让原始数据不经任何处理直接传到下一层。

这条直通道的关键是：数据通过时乘以 1。1 就是 1，不放大、不缩小、不改变。无论网络有多深，直通道里的数据始终保持原样。

这个设计叫"残差连接"，它支撑了过去十年几乎所有深度学习的成功，从图像识别到 ChatGPT。

3、HC：把固定的 1 变成可调的数字

残差连接虽然稳定，但它的直通道完全不参与学习，只是被动保底。能不能让它也"干点活"？

2024年提出的"超连接"（HC）做了这个尝试。它把直通道从一条扩展为四条，更关键的是：数据通过时不再乘以固定的 1，而是乘以一组网络自己学出来的数字。

可以把四条通道想象成调音台上的四个音轨。每一层可以调节这四个音轨怎么混合——把音轨 1 调小一点，音轨 2 调大一点，混出新的效果。怎么混最有效，是网络在训练中自己学出来的。

HC 的问题是：调节没有任何限制，可能把某个音轨放大太多，最后爆音；或者调得太小，声音消失。单独一层问题不大，但 60 层累积下来，论文实验显示放大倍数峰值达到了 3000。在 27B 参数模型训练中，HC 在约 12000 步时出现了崩溃迹象。

4、mHC：可以混音，但总音量守恒

mHC 沿用了 HC 的四音轨设计，也允许调节混合方式，但加了一条规矩：总音量必须不变。可以把音轨 1 调小、音轨 2 调大，但四个音轨加起来的总量必须和之前一样。现实中的调音台没有这个约束，这里只是借用来说明"可以重新分配，但总量守恒"的意思。

和残差连接的区别是：残差连接的数据完全不动；mHC 允许数据在通道之间重新分配。

和 HC 的区别是：HC 可以让数据凭空变多或变少；mHC 只能重新分配，不能增减总量。

总量不变，意味着每一层的放大倍数理论上是 1。实际工程中，为了计算效率，用的是一种近似算法，所以放大倍数是接近 1 的 1.6，而不是完美的 1。但比起 HC 的 3000，已经是天壤之别，训练全程稳定。

5、效果和代价

在 27B 参数模型的测试中，mHC 相比传统方案有明显提升：复杂推理任务从 43.8% 提升到 51.0%，阅读理解任务从 47.0% 提升到 53.9%。训练时间仅增加 6.7%。

6、这项工作的位置

论文将 mHC 定位为"HC 的灵活实用扩展"（a flexible and practical extension of HC）。在学术语境里，这是一个相当克制的自我评价：说"扩展"而不是"突破"，意味着这是在现有方法上的改进，而非全新的范式；说"实用"，强调的是工程上能落地，而非理论上的创新。这是一个解决了真实问题的扎实工作，DeepSeek 团队自己也没有过度包装。

对于大模型训练来说，这类"看起来不起眼但能避免崩溃"的改进，往往比花哨的新架构更有实际价值。

## 6

如果你见多识广，你就会对于“美军和日军在硫磺岛并肩作战”这种表述不会吃惊。

源田实，是山本五十六的主要参谋，很早就发现通过航母进行海上作战是未来的趋势。

他也是偷袭珍珠港的主要策划者。

战后，源田实并没有被清算，还担任了日本自卫队的空军幕僚长，相当于空军最高指挥官，中将的水平。

美国人给他颁发了一个勋章，将领级军团殊勋章。

这个勋章，是美国人给盟军颁发的最高勋章，获得该勋章的还有朱可夫、常凯申、瓦尔德斯•拉莫斯（曾担任菲律宾国防部长和总统）等等。

看看这几个人，你就知道这个勋章的份量了。

但是偷袭珍珠港的策划者也得了这个勋章，就让人很无语。

源田实受宠若惊，就推荐了李梅，给李梅颁发了日本的勋一等旭日大绶章。

李梅是谁呢？

李梅是美国人，在二战的时候，组织空袭日本，用燃烧弹炸日本本土，包括东京，烧死了20万日本人总有的。

这个勋章要天皇批准。

天皇死活不同意参加，反正要去，你们去，我才不去。

授勋仪式，李梅也没有参加，又没功劳，实在太不好意思了。

## 7

一般来说我对这种神棍政权的受害者都是无条件同情。但我最近接触了一些伊朗知识分子，也就是1979年勾结神棍喜迎霍梅尼那帮左棍的子女之后，有两个基本判断：1、他们的父母真是活逼该。2、一个国家的知识分子堕落到这种地步，老百姓就不必指望了，自下而上的暴力革命不可能产生任何新的，值得期待和称道的东西，大概率是下一个茅坑循环//@蒜泥猪头:目前还没有看到鹰犬武装丧失镇压能力的迹象，现在宣布神棍垮台为时尚早，谨慎乐观。

